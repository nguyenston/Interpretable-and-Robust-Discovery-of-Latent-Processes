\begin{abstract}
\end{abstract}

\begin{keyword}
The adoption of machine learning in critical domains such as healthcare and 
scientific discovery is hindered by a significant gap: while models excel at 
prediction, they often lack the interpretability and robustness required for 
high-stakes decision-making. This limitation stems from the difficulty 
of reliably identifying the unobserved, or latent, processes that govern complex systems, 
particularly when faced with imperfect data and unavoidable model misspecification. 
This work addresses this challenge by developing methodologies that 
shift the focus from predictive accuracy toward the robust and interpretable 
discovery of these latent structures. We present two primary contributions: 
(1) an asymptotically consistent spectral method of moments for 
Hierarchical Imitation Learning that provides a direct, 
reliable estimation of hidden decision-making policies, 
serving as both an asymptotically consistent standalone solution and 
a high-quality initialization that synergizes with 
Expectation-Maximization (EM) algorithms to prevent convergence to poor local optima, 
and (2) the Accumulated Cutoff Discrepancy Criterion (ACDC), 
a novel model selection framework that robustly identifies the true number 
of underlying processes by preventing overfitting to statistical noise and model artifacts. 
Collectively, these contributions advance 
a more robust and interpretable approach to machine learning, 
providing a powerful toolkit for meaningful scientific discovery.
\end{keyword}

