
@article{Dunson:2000,
year = {2000}, 
title = {{Bayesian latent variable models for clustered mixed outcomes}}, 
author = {Dunson, D. B.}, 
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, 
issn = {1369-7412}, 
doi = {10.1111/1467-9868.00236}, 
pages = {355--366}, 
number = {2}, 
volume = {62}, 
}
@article{Cunningham:2014,
year = {2014}, 
title = {{Dimensionality reduction for large-scale neural recordings}}, 
author = {Cunningham, John P and Yu, Byron M}, 
journal = {Nature Neuroscience}, 
issn = {1097-6256}, 
doi = {10.1038/nn.3776}, 
pages = {1500--1509}, 
number = {11}, 
volume = {17}, 
}

@article{Carvalho:2008,
author = {Carlos M. Carvalho and Jeffrey Chang and Joseph E. Lucas and Joseph R. Nevins and Quanli Wang and Mike West and},
title = {High-Dimensional Sparse Factor Modeling: Applications in Gene Expression Genomics},
journal = {Journal of the American Statistical Association},
volume = {103},
number = {484},
pages = {1438--1456},
year = {2008},
doi = {10.1198/016214508000000869},
}

@article{Chiou:2007,
year = {2007}, 
title = {{Functional clustering and identifying substructures of longitudinal data}}, 
author = {Chiou, Jeng‐Min and Li, Pai‐Ling}, 
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, 
issn = {1369-7412}, 
doi = {10.1111/j.1467-9868.2007.00605.x}, 
pages = {679--699}, 
number = {4}, 
volume = {69}, 
}
@article{West:2003, 
year = {2003}, 
title = {{Bayesian Factor Regression Models in the “Large p, Small n” Paradigm}}, 
author = {West, Mike}, 
journal = {Bayesian Statistics}, 
volume = {7}, 
}

@article{Blei:2007, 
year = {2007}, 
keywords = {topic modeling}, 
title = {{A correlated topic model of Science}}, 
author = {Blei, D. M. and Lafferty, J D}, 
journal = {The Annals of Applied Statistics}, 
doi = {10.1214/07-aoas114}, 
pages = {17 -- 35}, 
number = {1}, 
volume = {1}, 
language = {English}, 
}

@article{Shmueli:2010, 
year = {2010}, 
title = {{To Explain or to Predict?}}, 
author = {Shmueli, Galit}, 
journal = {Statistical Science}, 
doi = {10.1214/10-sts330}, 
pages = {289 -- 310}, 
number = {3}, 
volume = {25}, 
}

@Article{Helleday:2014,
  author          = {Helleday, Thomas and Eshtad, Saeed and Nik-Zainal, Serena},
  journal         = {Nature Reviews. Genetics},
  title           = {Mechanisms underlying mutational signatures in human cancers.},
  year            = {2014},
  issn            = {1471-0064},
  month           = sep,
  pages           = {585--598},
  volume          = {15},
  doi             = {10.1038/nrg3729},
  issue           = {9},
}

@Article{Koh:2021,
  author          = {Koh, Gene and Degasperi, Andrea and Zou, Xueqing and Momen, Sophie and Nik-Zainal, Serena},
  journal         = {Nature Reviews. Cancer},
  title           = {Mutational signatures: emerging concepts, caveats and clinical applications.},
  year            = {2021},
  issn            = {1474-1768},
  month           = oct,
  pages           = {619--637},
  volume          = {21},
  doi             = {10.1038/s41568-021-00377-7},
  issue           = {10},
}

@Article{Chakravarty:2021,
  author          = {Chakravarty, Debyani and Solit, David B.},
  journal         = {Nature Reviews. Genetics},
  title           = {Clinical cancer genomic profiling.},
  year            = {2021},
  issn            = {1471-0064},
  month           = aug,
  pages           = {483--501},
  volume          = {22},
  doi             = {10.1038/s41576-021-00338-8},
  issue           = {8},
}

@Article{pcawg2020,
  author          = {Alexandrov, Ludmil B. and Kim, Jaegil and Haradhvala, Nicholas J. and Huang, Mi Ni and Tian Ng, Alvin Wei and Wu, Yang and Boot, Arnoud and Covington, Kyle R. and Gordenin, Dmitry A. and Bergstrom, Erik N. and Islam, S. M. Ashiqul and Lopez-Bigas, Nuria and Klimczak, Leszek J. and McPherson, John R. and Morganella, Sandro and Sabarinathan, Radhakrishnan and Wheeler, David A. and Mustonen, Ville and {PCAWG Mutational Signatures Working Group} and Getz, Gad and Rozen, Steven G. and Stratton, Michael R. and {PCAWG Consortium}},
  journal         = {Nature},
  title           = {The repertoire of mutational signatures in human cancer.},
  year            = {2020},
  issn            = {1476-4687},
  month           = feb,
  pages           = {94--101},
  volume          = {578},
  doi             = {10.1038/s41586-020-1943-3},
  issue           = {7793},
}

@Article{pcawgSV:2020,
  author          = {Li, Yilong and Roberts, Nicola D. and Wala, Jeremiah A. and Shapira, Ofer and Schumacher, Steven E. and Kumar, Kiran and Khurana, Ekta and Waszak, Sebastian and Korbel, Jan O. and Haber, James E. and Imielinski, Marcin and {PCAWG Structural Variation Working Group} and Weischenfeldt, Joachim and Beroukhim, Rameen and Campbell, Peter J. and {PCAWG Consortium}},
  journal         = {Nature},
  title           = {Patterns of somatic structural variation in human cancer genomes.},
  year            = {2020},
  issn            = {1476-4687},
  month           = feb,
  pages           = {112--121},
  volume          = {578},
  doi             = {10.1038/s41586-019-1913-9},
  issue           = {7793},
}

@article{Drossos:1980,
	abstract = {It is shown that minimum distance estimates enjoy the invariance property of maximum likelihood estimates.},
	author = {Drossos, Constantine A. and Philippou, Andreas N.},
	doi = {10.1007/BF02480318},
	isbn = {1572-9052},
	journal = {Annals of the Institute of Statistical Mathematics},
	number = {1},
	pages = {121--123},
	title = {A note on minimum distance estimates},
	url = {https://doi.org/10.1007/BF02480318},
	volume = {32},
	year = {1980}}


@article{Wolfowitz:1957, 
year = {1957}, 
title = {{The Minimum Distance Method}}, 
author = {Wolfowitz, J.}, 
journal = {The Annals of Mathematical Statistics}, 
issn = {0003-4851}, 
doi = {10.1214/aoms/1177707038}, 
pages = {75--88}, 
number = {1}, 
volume = {28}, 
}

@article{Parr:1980, 
year = {1980}, 
title = {{Minimum Distance and Robust Estimation}}, 
author = {Parr, William C. and Schucany, William R.}, 
journal = {Journal of the American Statistical Association}, 
issn = {0162-1459}, 
doi = {10.1080/01621459.1980.10477522}, 
pages = {616--624}, 
number = {371}, 
volume = {75}, 
}


@article{Perkel:2019,
	title={Julia: come for the syntax, stay for the speed},
	author={Perkel, Jeffrey M and others},
	journal={Nature},
	volume={572},
	number={7767},
	pages={141--142},
	year={2019},
	publisher={Springer Science and Business Media LLC}
}



@article{Wang:2019,
	author = {Yixin Wang and David M. Blei},
	title = {Frequentist Consistency of Variational Bayes},
	journal = {Journal of the American Statistical Association},
	volume = {114},
	number = {527},
	pages = {1147-1161},
	year = {2019},
	publisher = {Taylor & Francis}
}

@InProceedings{Krause:2023,
	title = 	 {Optimally-weighted Estimators of the Maximum Mean Discrepancy for Likelihood-Free Inference},
	author =       {Bharti, Ayush and Naslidnyk, Masha and Key, Oscar and Kaski, Samuel and Briol, Francois-Xavier},
	booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
	pages = 	 {2289--2312},
	year = 	 {2023},
	editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
	volume = 	 {202},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {23--29 Jul},
	publisher =    {PMLR},
}


@article{Simon:2020,
title = {Metrizing Weak Convergence with Maximum Mean Discrepancies},
author = {Simon-Gabriel, C.-J. and Barp, A. and Sch{\"o}lkopf, B. and Mackey, L.},
journal = {Journal of Machine Learning Research},
volume = {24},
year = {2023},
doi = {},
url = {https://www.jmlr.org/papers/volume24/21-0599/21-0599.pdf}
}

@article{Paninski:2003,
	author = {Paninski, Liam},
	year = {2003},
	month = {06},
	pages = {1191-1253},
	title = {Estimation of Entropy and Mutual Information},
	volume = {15},
	journal = {Neural Computation},
	doi = {10.1162/089976603321780272}
}


@article{Donoho:2000,
	author = {Donoho, David},
	year = {2000},
	month = {01},
	pages = {1-32},
	title = {High-Dimensional Data Analysis: The Curses and Blessings of Dimensionality},
	journal = {AMS Math Challenges Lecture}
}

@book{Berger:2013,
	title={Statistical decision theory and Bayesian analysis},
	author={Berger, James O},
	year={2013},
	publisher={Springer Science \& Business Media}
}

@article{Souto:2008,
	title={Clustering cancer gene expression data: a comparative study},
	author={Marc{\'i}lio Carlos Pereira de Souto and Ivan G. Costa and Daniel S. A. de Araujo and Teresa Bernarda Ludermir and Alexander Schliep},
	journal={BMC Bioinformatics},
	year={2008},
	volume={9},
	pages={497 - 497},
	url={https://api.semanticscholar.org/CorpusID:9941351}
}

@article{Walker:2001,
	author = {Walker, Stephen and Hjort, Nils Lid},
	title = {On Bayesian consistency},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	volume = {63},
	number = {4},
	pages = {811-821},
	keywords = {Asymptotics, Bayesian sieve, Bayes nonparametrics, Consistency},
	doi = {https://doi.org/10.1111/1467-9868.00314},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00314},
	eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9868.00314},
	year = {2001}
}




@article{Balakrishnan:2017,
	author = {Sivaraman Balakrishnan and Martin J. Wainwright and Bin Yu},
	title = {{Statistical guarantees for the EM algorithm: From population to sample-based analysis}},
	volume = {45},
	journal = {The Annals of Statistics},
	number = {1},
	publisher = {Institute of Mathematical Statistics},
	pages = {77 -- 120},
	keywords = {EM algorithm, first-order EM algorithm, maximum likelihood estimation, nonconvex optimization},
	year = {2017},
	doi = {10.1214/16-AOS1435},
	URL = {https://doi.org/10.1214/16-AOS1435}
}



@inproceedings{Chen:1998,
	title={Clustering via the Bayesian information criterion with applications in speech recognition},
	author={Chen, Scott Shaobing and Gopalakrishnan, Ponani S},
	booktitle={Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP'98 (Cat. No. 98CH36181)},
	volume={2},
	pages={645--648},
	year={1998},
	organization={IEEE}
}
@article{SimonGabriel:2018, 
year = {2018}, 
title = {{Kernel Distribution Embeddings - Universal Kernels, Characteristic Kernels and Kernel Metrics on Distributions.}}, 
author = {Simon-Gabriel, Carl-Johann and Sch\"{o}lkopf, Bernhard}, 
journal = {Journal of Machine Learning Research}, 
pages = {1 -- 29}, 
number = {44},
volume = {19}, 
}


@article{Sriperumbudur:2010, 
year = {2010}, 
title = {{Hilbert Space Embeddings and Metrics on Probability Measures}}, 
author = {Sriperumbudur, Bharath K and Gretton, A. and Fukumizu, K. and Sch\"{o}lkopf, Bernhard and Lanckriet, G R G}, 
journal = {Journal of Machine Learning Research}, 
pages = {1517 -- 1561}, 
volume = {11}, 
}

@book{Villani:2009, 
            year = {2009}, 
            title = {{Optimal transport: old and new}}, 
            author = {Villani, C}, 
            isbn = {3540710507}, 
            volume = {338}, 
            publisher = {Springer}, 
}

@incollection{Joyce:2011,
	title={Kullback-leibler divergence},
	author={Joyce, James M},
	booktitle={International encyclopedia of statistical science},
	pages={720--722},
	year={2011},
	publisher={Springer}
}


@article{Cai:2020,
	title={Distances Between Probability Distributions of Different Dimensions},
	author={Yuhan Cai and Lek-Heng Lim},
	journal={IEEE Transactions on Information Theory},
	year={2020},
	volume={68},
	pages={4020-4031}
}

@article{Gretton:2012,
	author  = {Arthur Gretton and Karsten M. Borgwardt and Malte J. Rasch and Bernhard Sch{{\"o}}lkopf and Alexander Smola},
	title   = {A Kernel Two-Sample Test},
	journal = {Journal of Machine Learning Research},
	year    = {2012},
	volume  = {13},
	number  = {25},
	pages   = {723-773},
	url     = {http://jmlr.org/papers/v13/gretton12a.html}
}

@book{Vaart:1996,
	title={Weak Convergence and Empirical Processes: With Applications to Statistics},
	author={van der Vaart, AW and Wellner, J.},
	isbn={9780387946405},
	lccn={95049099},
	series={Springer Series in Statistics},
	url={https://books.google.com/books?id=OCenCW9qmp4C},
	year={1996},
	publisher={Springer}
}


@article{Brinkman:2007,
	author = {Brinkman, William and Geraghty, Sheela and Lanphear, Bruce and Khoury, Jane and Rey, Javier and Dewitt, Thomas and Britto, Maria},
	year = {2007},
	month = {02},
	pages = {44-9},
	title = {Effect of Multisource Feedback on Resident Communication Skills and Professionalism},
	volume = {161},
	journal = {Archives of pediatrics \& adolescent medicine},
}

@book{Fruhwurth:2006,
	title={Finite Mixture and Markov Switching Models},
	author={Fr{\"u}hwirth-Schnatter, S.},
	isbn={9780387357683},
	lccn={2006923106},
	series={Springer Series in Statistics},
	url={https://books.google.com/books?id=f8KiI7eRjYoC},
	year={2006},
	publisher={Springer New York}
}

@article{Gibbs:2002,
	 author = {Alison L. Gibbs and Francis Edward Su},
	journal = {International Statistical Review},
	number = {3},
	pages = {419--435},
	title = {On Choosing and Bounding Probability Metrics},
	volume = {70},
	year = {2002}
}


@INPROCEEDINGS{Zhao:2020,  
	author={Zhao, Puning and Lai, Lifeng},  booktitle={2020 IEEE International Symposium on Information Theory (ISIT)},   title={Analysis of K Nearest Neighbor KL Divergence Estimation for Continuous Distributions},   year={2020},  volume={},  number={},  pages={2562-2567},  doi={10.1109/ISIT44484.2020.9174033}}

@article{Jain:2004,
	author = {Sonia Jain and Radford M. Neal},
	journal = {Journal of Computational and Graphical Statistics},
	number = {1},
	pages = {158--182},
	publisher = {[American Statistical Association, Taylor & Francis, Ltd., Institute of Mathematical Statistics, Interface Foundation of America]},
	title = {A Split-Merge Markov Chain Monte Carlo Procedure for the Dirichlet Process Mixture Model},
	volume = {13},
	year = {2004}
}


@article{Wellner:1981,
	title = {A Glivenko-Cantelli theorem for empirical measures of independent but non-identically distributed random variables},
	journal = {Stochastic Processes and their Applications},
	volume = {11},
	number = {3},
	pages = {309-312},
	year = {1981},
	author = {Jon A. Wellner},
}


@InProceedings{Abdellatif:2020,
	title = 	 {MMD-Bayes: Robust Bayesian Estimation via Maximum
	Mean Discrepancy},
	author =       {Cherief-Abdellatif, Badr-Eddine and Alquier, Pierre},
	booktitle = 	 {Proceedings of The 2nd Symposium on
	Advances in Approximate Bayesian Inference},
	pages = 	 {1--21},
	year = 	 {2020},
	volume = 	 {118},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {08 Dec},
	publisher =    {PMLR},
}


@article{Diaconis:1982,
	author = { Persi   Diaconis  and  Sandy L.   Zabell },
	title = {Updating Subjective Probability},
	journal = {Journal of the American Statistical Association},
	volume = {77},
	number = {380},
	pages = {822-830},
	year  = {1982},
	publisher = {Taylor & Francis},
	doi = {10.1080/01621459.1982.10477893}	
}
 


@article{Gorsky:2020,
	author = {Gorsky, Shai and Chan, Cliburn and Ma, Li},
	year = {2020},
	month = {01},
	pages = {},
	 Journal = {arXiv},
	title = {Coarsened mixtures of hierarchical skew normal kernels for flow cytometry analyses}
}
 


@article{Ghorbani:2016,
	title = {Cardiac arrhythmia classification using statistical and mixture modeling features of ECG signals},
	journal = {Pattern Recognition Letters},
	volume = {70},
	pages = {45-51},
	year = {2016},
	issn = {0167-8655},
	doi = {https://doi.org/10.1016/j.patrec.2015.11.018},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865515004043},
	author = {Rashid {Ghorbani Afkhami} and Ghanbar Azarnia and Mohammad Ali Tinati},
}

@InProceedings{Prabhakaran:2016,
	title = 	 {Dirichlet Process Mixture Model for Correcting Technical Variation in Single-Cell Gene Expression Data},
	author = 	 {Prabhakaran, Sandhya and Azizi, Elham and Carr, Ambrose and Pe’er, Dana},
	booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
	pages = 	 {1070--1079},
	year = 	 {2016},
	editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
	volume = 	 {48},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {New York, New York, USA},
	month = 	 {20--22 Jun},
	publisher =    {PMLR}
}

@article{Mitianoudis:2015,
	title = {Document image binarization using local features and Gaussian mixture modeling},
	journal = {Image and Vision Computing},
	volume = {38},
	pages = {33-51},
	year = {2015},
	issn = {0262-8856},
	doi = {https://doi.org/10.1016/j.imavis.2015.04.003},
	url = {https://www.sciencedirect.com/science/article/pii/S0262885615000360},
	author = {Nikolaos Mitianoudis and Nikolaos Papamarkos},
}

@article{Channoufi:2018,
	title = { Image and video denoising by combining unsupervised bounded generalized gaussian mixture modeling and spatial information},
	journal = {Multimed Tools Appl},
	volume = {77},
	pages = {25591–25606 },
	year = {2018},
	doi = {https://doi.org/10.1007/s11042-018-5808-9},
	author = {Channoufi, I. and Bourouis, S. and Bouguila, N. et al}
}




@ARTICLE{Greenspan:2006,  
	author={Greenspan, H. and Ruf, A. and Goldberger, J.},  
	journal={IEEE Transactions on Medical Imaging},   
	title={Constrained Gaussian mixture model framework for automatic segmentation of MR brain images},   
	year={2006},  
	volume={25},  
	number={9},  
	pages={1233-1245}}




@article{Adelino:2007,
	title = {A Dirichlet process mixture model for brain MRI tissue classification},
	journal = {Medical Image Analysis},
	volume = {11},
	number = {2},
	pages = {169-182},
	year = {2007},
	issn = {1361-8415},
	author = {Adelino R. {Ferreira da Silva}},
}


@inproceedings{
	Zong:2018,
	title={Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection},
	author={Bo Zong and Qi Song and Martin Renqiang Min and Wei Cheng and Cristian Lumezanu and Daeki Cho and Haifeng Chen},
	booktitle={International Conference on Learning Representations},
	year={2018},
	url={https://openreview.net/forum?id=BJJLHbb0-},
}

@article{Durand:2022,
	title = {Heterogeneity in speed of adjustment using finite mixture models},
	journal = {Economic Modelling},
	volume = {107},
	pages = {105713},
	year = {2022},
	issn = {0264-9993},
	doi = {https://doi.org/10.1016/j.econmod.2021.105713},
	url = {https://www.sciencedirect.com/science/article/pii/S0264999321003023},
	author = {Robert B. Durand and William H. Greene and Mark N. Harris and Joye Khoo},
}


@article{Link:2018,
	author = {Link, William A. and Schofield, Matthew R. and Barker, Richard J. and Sauer, John R.},
	title = {On the robustness of N-mixture models},
	journal = {Ecology},
	volume = {99},
	number = {7},
	pages = {1547-1551},
	keywords = {abundance estimation, Bayesian P-value, count data, detection probability, N-mixture model, robustness},
	doi = {https://doi.org/10.1002/ecy.2362},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecy.2362},
	eprint = {https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1002/ecy.2362},
	year = {2018}
}


@article{Stevens:2019,
	title = {Identification and analysis of behavioral phenotypes in autism spectrum disorder via unsupervised machine learning},
	journal = {International Journal of Medical Informatics},
	volume = {129},
	pages = {29-36},
	year = {2019},
	issn = {1386-5056},
	doi = {https://doi.org/10.1016/j.ijmedinf.2019.05.006},
	url = {https://www.sciencedirect.com/science/article/pii/S1386505618308669},
	author = {Elizabeth Stevens and Dennis R. Dixon and Marlena N. Novack and Doreen Granpeesheh and Tristram Smith and Erik Linstead},
}


@article{Geweke:2011,
	author = {Geweke, John and Amisano, Gianni},
	title = {Hierarchical Markov normal mixture models with applications to financial asset returns},
	journal = {Journal of Applied Econometrics},
	volume = {26},
	number = {1},
	pages = {1-29},
	doi = {https://doi.org/10.1002/jae.1119},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.1119},
	year = {2011}
}

@article{Bauer:2007,
	author = { Daniel J.   Bauer },
	title = {Observations on the Use of Growth Mixture Models in Psychological Research},
	journal = {Multivariate Behavioral Research},
	volume = {42},
	number = {4},
	pages = {757-786},
	year  = {2007},
	publisher = {Routledge},
	doi = {10.1080/00273170701710338},	
	URL = { 
	https://doi.org/10.1080/00273170701710338},
	eprint = { 
	https://doi.org/10.1080/00273170701710338}
}

@article{Mouret:2022,
	title = {Reconstruction of Sentinel-2 derived time series using robust Gaussian mixture models — Application to the detection of anomalous crop development},
	journal = {Computers and Electronics in Agriculture},
	volume = {198},
	pages = {106983},
	year = {2022},
	issn = {0168-1699},
	doi = {https://doi.org/10.1016/j.compag.2022.106983},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169922003003},
	author = {Florian Mouret and Mohanad Albughdadi and Sylvie Duthoit and Denis Kouamé and Guillaume Rieu and Jean-Yves Tourneret},
}


@article{Chaumeny:2022,
	author = {Chaumeny, Yannis and Moris, Johan and Davison, Anthony and Kirk, Paul},
	year = {2022},
	month = {07},
	pages = {},
	title = {Bayesian nonparametric mixture inconsistency for the number of components: How worried should we be in practice?},
	doi = {10.48550/arXiv.2207.14717}
}


@article{Liu:2003,
	author = {Xin Liu and Yongzhao Shao},
	title = {{Asymptotics for likelihood ratio tests under loss of identifiability}},
	volume = {31},
	journal = {The Annals of Statistics},
	number = {3},
	publisher = {Institute of Mathematical Statistics},
	pages = {807 -- 832},
	keywords = {Donsker class, Finite mixture model, Hellinger distance, likelihood ratio test, loss of identifiability},
	year = {2003},
	doi = {10.1214/aos/1056562463},
	URL = {https://doi.org/10.1214/aos/1056562463}
}

@article{Miller:2014,
	author  = {Jeffrey W. Miller and Matthew T. Harrison},
	title   = {Inconsistency of Pitman-Yor Process Mixtures for the Number of Components},
	journal = {Journal of Machine Learning Research},
	year    = {2014},
	volume  = {15},
	number  = {96},
	pages   = {3333--3370},
	url     = {http://jmlr.org/papers/v15/miller14a.html}
}


@article{Schwarz:1978,
	author = {Gideon Schwarz},
	journal = {The Annals of Statistics},
	number = {2},
	pages = {461--464},
	publisher = {Institute of Mathematical Statistics},
	title = {Estimating the Dimension of a Model},
	urldate = {2022-10-11},
	volume = {6},
	year = {1978}
}
@article{Spiegelhalter:2002,
	author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and Van Der Linde, Angelika},
	title = {Bayesian measures of model complexity and fit},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	volume = {64},
	number = {4},
	pages = {583-639},
	year = {2002}
}



@article{Celeux:2006,
	author = {G. Celeux and F. Forbes and C. P. Robert and D. M. Titterington},
	title = {{Deviance information criteria for missing data models}},
	volume = {1},
	journal = {Bayesian Analysis},
	number = {4},
	publisher = {International Society for Bayesian Analysis},
	pages = {651 -- 673},
	keywords = {completion, deviance, DIC, EM algorithm, MAP, mixture model, model comparison, random effect model},
	year = {2006},
	doi = {10.1214/06-BA122},
	URL = {https://doi.org/10.1214/06-BA122}
}

@book{Schnatter:2006,
	added-at = {2013-01-07T16:10:56.000+0100},
	address = {Berlin},
	author = {Fr\"uhwirth-Schnatter, S.},
	biburl = {https://www.bibsonomy.org/bibtex/2969b884bf1e3884eed20374ea0bf2273/olivia.bluder},
	edition = {1st},
	keywords = {imported},
	owner = {bluder},
	publisher = {Springer},
	timestamp = {2013-01-07T16:11:02.000+0100},
	title = {Finite mixture and {M}arkov switching models},
	year = {2006}
}


@article{Roeder:1997,
	author = {Kathryn Roeder and Larry Wasserman},
	journal = {Journal of the American Statistical Association},
	number = {439},
	pages = {894--902},
	publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
	title = {Practical Bayesian Density Estimation Using Mixtures of Normals},
	urldate = {2022-10-11},
	volume = {92},
	year = {1997}
}
@ARTICLE{Akaike:1974,  
	author={Akaike, H.},  
	journal={IEEE Transactions on Automatic Control},   
	title={A new look at the statistical model identification},   
	year={1974},  
	volume={19},  
	number={6},  
	pages={716-723},  
	doi={10.1109/TAC.1974.1100705}}

@article{Keribin:2000,
	author = {Keribin, Christine},
	year = {2000},
	month = {01},
	pages = {49-62},
	title = {Consistent Estimation of the Order of Mixture Models},
	volume = {62},
	journal = {Sankhya, Series A}
}


@inproceedings{PerezCruz:2008,
	author = {P\'{e}rez-Cruz, Fernando},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Estimation of Information Theoretic Measures for Continuous Random Variables},
	url = {https://proceedings.neurips.cc/paper/2008/file/ccb0989662211f61edae2e26d58ea92f-Paper.pdf},
	volume = {21},
	year = {2008}
}


@article{Huber:1984,
	author = {Peter J. Huber},
	title = {{Finite Sample Breakdown of $M$- and $P$-Estimators}},
	volume = {12},
	journal = {The Annals of Statistics},
	number = {1},
	publisher = {Institute of Mathematical Statistics},
	pages = {119 -- 126},
	keywords = {$M$-estimators, $P$-estimators, Breakdown point, redescending estimators, robustness},
	year = {1984},
	doi = {10.1214/aos/1176346396},
	URL = {https://doi.org/10.1214/aos/1176346396}
}


@article{Wang:2018,
	author = {Chong Wang and David M. Blei},
	title = {{A General Method for Robust Bayesian Modeling}},
	volume = {13},
	journal = {Bayesian Analysis},
	number = {4},
	publisher = {International Society for Bayesian Analysis},
	pages = {1163 -- 1191},
	keywords = {Empirical Bayes, expectation-maximization, generalized linear models, probabilistic models, robust statistics, topic models, variational inference},
	year = {2018},
	doi = {10.1214/17-BA1090},
	URL = {https://doi.org/10.1214/17-BA1090}
}


@inproceedings{Christopher:2004,
	title={Robust Bayesian Mixture Modelling.},
	author={Bishop, Christopher M and Svens{\'e}n, Markus},
	booktitle={ESANN},
	pages={69--74},
	year={2004},
	organization={Citeseer}
}

@article{Archambeau:2007,
	title = {Robust Bayesian clustering},
	journal = {Neural Networks},
	volume = {20},
	number = {1},
	pages = {129-138},
	year = {2007},
	issn = {0893-6080},
	doi = {https://doi.org/10.1016/j.neunet.2006.06.009},
	author = {Cédric Archambeau and Michel Verleysen},
}
@article{Miller:2019,
	author = {Jeffrey W. Miller and David B. Dunson},
	title = {Robust Bayesian Inference via Coarsening},
	journal = {Journal of the American Statistical Association},
	volume = {114},
	number = {527},
	pages = {1113-1125},
	year  = {2019},
	publisher = {Taylor & Francis},
	doi = {10.1080/01621459.2018.1469995},
	}
@book{Celeux:2018,
	author = {Celeux, Gilles and Frühwirth-Schnatter, Sylvia and Robert, Christian},
	year = {2018},
	month = {12},
	pages = {},
	title = {Model Selection for Mixture Models-Perspectives and Strategies}
}

@article{Mena:2015,
	author = {Ramsés H. Mena and Stephen G. Walker},
	journal = {Journal of Computational and Graphical Statistics},
	number = {4},
	pages = {1155--1169},
	title = {On the Bayesian Mixture Model and Identifiability},
	volume = {24},
	year = {2015}
}


@article{Guha:2021,
	author = {Aritra Guha and Nhat Ho and XuanLong Nguyen},
	title = {{On posterior contraction of parameters and interpretability in Bayesian mixture modeling}},
	volume = {27},
	journal = {Bernoulli},
	number = {4},
	publisher = {Bernoulli Society for Mathematical Statistics and Probability},
	pages = {2159 -- 2188},
	keywords = {Bayesian inference, Bayesian nonparametrics, misspecified models, Mixture models, post-processing algorithm, Wasserstein distance},
	year = {2021},
	doi = {10.3150/20-BEJ1275},
	URL = {https://doi.org/10.3150/20-BEJ1275}
}


@article{Nguyen:2013,
	author = {XuanLong Nguyen},
	title = {{Convergence of latent mixing measures in finite and infinite mixture models}},
	volume = {41},
	journal = {The Annals of Statistics},
	number = {1},
	publisher = {Institute of Mathematical Statistics},
	pages = {370 -- 400},
	keywords = {$f$-divergence, Bayesian nonparametrics, Dirichlet processes, hierarchical models, mixture distributions, rates of convergence, transportation distances, Wasserstein metric},
	year = {2013},
	doi = {10.1214/12-AOS1065},
	URL = {https://doi.org/10.1214/12-AOS1065}
}



@article{Dacunha-Castelle:1997,
	author = {Didier Dacunha-Castelle and Elisabeth Gassiat},
	journal = {Bernoulli},
	number = {3},
	pages = {279--299},
	publisher = {International Statistical Institute (ISI) and Bernoulli Society for Mathematical Statistics and Probability},
	title = {The Estimation of the Order of a Mixture Model},
	urldate = {2022-10-10},
	volume = {3},
	year = {1997}
}

@InProceedings{Cai:2021,
	title = 	 {Finite mixture models do not reliably learn the number of components},
	author =       {Cai, Diana and Campbell, Trevor and Broderick, Tamara},
	booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
	pages = 	 {1158--1169},
	year = 	 {2021},
	editor = 	 {Meila, Marina and Zhang, Tong},
	volume = 	 {139},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {18--24 Jul},
	publisher =    {PMLR},
}


@article{Gassiat:2002,
	author = {Gassiat, Elisabeth},
	title = {Likelihood ratio inequalities with applications to various mixtures},
	journal = {Annales de l'I.H.P. Probabilit\'es et statistiques},
	pages = {897--906},
	publisher = {Elsevier},
	volume = {38},
	number = {6},
	year = {2002},
	zbl = {1011.62025},
	mrnumber = {1955343},
	language = {en},
	url = {http://www.numdam.org/item/AIHPB_2002__38_6_897_0/}
}

@article{McLachlan:1987,
	ISSN = {00359254, 14679876},
	author = {G. J. McLachlan},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	number = {3},
	pages = {318--324},
	publisher = {[Wiley, Royal Statistical Society]},
	title = {On Bootstrapping the Likelihood Ratio Test Stastistic for the Number of Components in a Normal Mixture},
	urldate = {2022-10-10},
	volume = {36},
	year = {1987}
}


 @Book{McLachlan:2000,
	author =   {Geoffrey J. McLachlan, David Peel},
	title =    {Finite Mixture Models},
	publisher =    {New York: Wiley},
	year =     {2000},
}

 @Book{Anderberg83,
   author =   {Anderberg, M. R.},
   title =    {Cluster Analysis for Applications},
   publisher =    {New York: Academic Press},
   year =     {1983},
 }

@article{Berrendero.etal:2015,
	Author = {Berrendero, J. R., Cuevas, A. \& Torrecilla, J. L.},
	Title = {On the use of reproducing kernel Hilbert spaces in functional classification},
	Journal = {arXiv},
	Pages = {1507.04398v3},
	Year = {2015}
}


  @Manual{R:2010,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Development Core Team}},
    organization = {Vienna, Austria: R Foundation for Statistical Computing},
    address = {},
    year = {2012},
    note = {{ISBN} 3-900051-07-0, http://www.R-project.org},
    url = {http://www.R-project.org},
  }

  @Manual{R:2008,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Development Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2008},
    note = {{ISBN} 3-900051-07-0},
    url = {http://www.R-project.org},
  }

  @Article{Arabie80,
   author =   {Arabie, P. and Carroll, J. D.},
   title =    {MAPCLUS: A mathematical programming approach to fitting the ADCLUS models},
   journal =      {Psychometrika},
   year =     {1980 },
   volume =   {445},
   pages =    {211-35},
 }


@book{Tufte:1990,
    Address = {Cheshire, Connecticut},
    Author = {E. R. Tufte},
    Publisher = {Graphics Press},
    Title = {{Envisioning Information}},
    Year = {1990}}


@book{Tufte:1983,
    Address = {Cheshire},
    Author = {E. R. Tufte},
    Publisher = {Graphics Press},
    Title = {{The Visual Display of Quantitative Information}},
    Year = {1983}}

@book{Cleveland:1994,
    Address = {Summit},
    Author = {W. S. Cleveland},
    Edition = {Revised},
    Publisher = {Hobart Press},
    Title = {{The Elements of Graphing Data}},
    Year = {1994}}

@book{Cleveland:1993,
    Address = {Summit},
    Author = {W. S. Cleveland},
    Publisher = {Hobart Press},
    Title = {{Vizualizing Data}},
    Year = {1993}}

 @TECHREPORT{Ball65 ,
   AUTHOR =       {Ball, G. H. and Hall, D. J. },
   TITLE =        {A novel method of data analysis and pattern classification },
   INSTITUTION =  {Stanford Research Institute, California },
   YEAR =         {1965 },
 }

 @Article{Banfield93,
   author =   {Banfield, J. D. and Raftery, A. E.},
   title =    {Model-Based Gaussian and Non-Gaussian Clustering },
   journal =      {Biometrics },
   year =     {1993 },
   volume =   {49},
   pages =    {803--21},
 }

 @Article{Beale69,
   author =   {Beale, E. M. L.},
   title =    {Euclidean cluster analysis },
   journal =      {Bulletin of the International Statistical Institute },
   year =     {1969 },
   volume =   {43},
   pages =    {92-94},
 }

 @Article{Bensmail,
   author =   {Bensmail, H. },
   title =    {Model-based Clustering with Noise: Bayesian inference and estimation },
 }

@Article{Bezdek74,
   author =   {Bezdek, J. C.},
   title =    {Numerical taxonomy with fuzzy sets},
   journal =      {Journal of Methematical Biology},
   year =     {1974},
   volume =   {1},
   pages =    {57-71},
 }
@article{Forero:2011,
	author = {Forero, Pedro and Kekatos, Vassilis and Giannakis, G.B.},
	year = {2011},
	month = {04},
	pages = {},
	title = {Robust Clustering Using Outlier-Sparsity Regularization},
	volume = {60},
	journal = {Computing Research Repository - CORR},
	doi = {10.1109/TSP.2012.2196696}
}
@article{Cox:1972,
    Author = {D. R. Cox},
    Journal = {J. R. Statist. Soc. {\rm B}},
    Pages = {187--220},
    Title = {{Regression models and life tables (with Discussion)}},
    Volume = {34},
    Year = {1972}}

@article{Hear:Holm:Step:quan:2006,
    Author = {Heard, Nicholas A. and Holmes, Christopher C. and Stephens, David A.},
    Journal = {J. Am. Statist. Assoc.},
    Keywords = {bayesian hierarchical clustering; gene expression profiles; Microarrays},
    Pages = {18--29},
    Title = {A Quantitative Study of Gene Regulation Involved in the Immune Response of {A}nopheline Mosquitoes: {A}n Application of {B}ayesian Hierarchical Clustering of Curves},
    Volume = {101},
    Year = {2006}}

@article{Fan:2004,
    Author = {Fan, J. and Peng, H.},
    Journal = {Ann. Statist.},
    Pages = {928--61},
    Title = {{Nonconcave penalized likelihood with a diverging number of parameters}},
    Volume = {32},
    Year = {2004}}


%% Created using Papers on Wed, 21 Oct 2020.
%% http://papersapp.com/papers/

@article{Wang:2009,
	author = {Wang, Qing and Kulkarni, Sanjeev and Verdú, Sergio},
	year = {2009},
	month = {06},
	pages = {2392 - 2405},
	title = {Divergence Estimation for Multidimensional Densities Via -Nearest-Neighbor Distances},
	volume = {55},
	journal = {Information Theory, IEEE Transactions on},
}



@article{Devroye:1977,
	author = {Luc P. Devroye and T. J. Wagner},
	title = {{The Strong Uniform Consistency of Nearest Neighbor Density Estimates}},
	volume = {5},
	journal = {The Annals of Statistics},
	number = {3},
	publisher = {Institute of Mathematical Statistics},
	pages = {536 -- 540},
	keywords = {consistency, multivariate density estimation, Nonparametric density estimation, uniform consistency},
	year = {1977},
	doi = {10.1214/aos/1176343851},
	URL = {https://doi.org/10.1214/aos/1176343851}
}

@article{Beirlant:1997,
	author = {Beirlant, Jan and Dudewicz, E. and Gyor, L. and Meulen, E.C.},
	year = {1997},
	month = {01},
	pages = {},
	title = {Nonparametric Entropy Estimation: An Overview},
	volume = {6},
	journal = {International Journal of Mathematical and Statistical Sciences}
}


@article{Hall:1987,
	URL = {http://www.jstor.org/stable/2241687},
	
	author = {Peter Hall},
	journal = {The Annals of Statistics},
	number = {4},
	pages = {1491--1519},
	publisher = {Institute of Mathematical Statistics},
	title = {On Kullback-Leibler Loss and Density Estimation},
	urldate = {2023-02-01},
	volume = {15},
	year = {1987}
}

@article{Hall:1993,
	title = {On the estimation of entropy},
	author = {Peter Hall and Morton, Sally C.},
	year = {1993},
	volume = {45},
	pages = {69--88},
	journal = {Annals of the Institute of Statistical Mathematics},
	publisher = {Springer Netherlands},
	number = {1},
}


@article{Gyorfi:1987,
	number = {4},
	title = {Density-free convergence properties of various estimators of entropy},
	volume = {5},
	year = {1987},
	author = {Györfi, L and van der Meulen, EC},
	journal = {Computational Statistics and Data Analysis},
}

@article{Gyorfi:1989,
	title={An entropy estimate based on a kernel density estimation},
	author={Györfi, L and van der Meulen, EC},
	journal={Limit Theorems in Probability and Statistics},
	pages={229--240},
	year = {1989},
	publisher={North-Holland Amsterdam}
}


@article{Gyorfi:1991,
	title={On the nonparametric estimation of the entropy functional},
	author={Györfi, L and van der Meulen, EC},
	journal={Nonparametric functional estimation and related topics},
	pages={81--95},
	year = {1991},
	publisher={Kluwer}
}

%%% application section

@article {sc3,
	author = {Kiselev, Vladimir Yu. and Kirschner, Kristina and Schaub, Michael T. and Andrews, Tallulah and Chandra, Tamir and Natarajan, Kedar N and Reik, Wolf and Barahona, Mauricio and Green, Anthony R and Hemberg, Martin},
	title = {SC3 {\textendash} consensus clustering of single-cell RNA-Seq data},
	elocation-id = {036558},
	year = {2016},
	doi = {10.1101/036558},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {},
	URL = {https://www.biorxiv.org/content/early/2016/01/13/036558},
	eprint = {https://www.biorxiv.org/content/early/2016/01/13/036558.full.pdf},
	journal = {bioRxiv}
}

@Article{seurat,
    author = {Andrew Butler and Paul Hoffman and Peter Smibert and
      Efthymia Papalexi and Rahul Satija},
    title = {Integrating single-cell transcriptomic data across
      different conditions, technologies, and species},
    journal = {Nature Biotechnology},
    year = {2018},
    volume = {36},
    pages = {411-420},
    doi = {10.1038/nbt.4096},
    url = {https://doi.org/10.1038/nbt.4096},
}

@article {mice,
	author = {Schaum, Nicholas and Karkanias, Jim and Neff, Norma F and May, Andrew P. and Quake, Stephen R. and Wyss-Coray, Tony and Darmanis, Spyros and Batson, Joshua and Botvinnik, Olga and Chen, Michelle B. and Chen, Steven and Green, Foad and Jones, Robert and Maynard, Ashley and Penland, Lolita and Sit, Rene V. and Stanley, Geoffrey M. and Webber, James T. and Zanini, Fabio and Baghel, Ankit S. and Bakerman, Isaac and Bansal, Ishita and Berdnik, Daniela and Bilen, Biter and Brownfield, Douglas and Cain, Corey and Chen, Michelle B. and Chen, Steven and Cho, Min and Cirolia, Giana and Conley, Stephanie D. and Darmanis, Spyros and Demers, Aaron and Demir, Kubilay and Morree, Antoine de and Divita, Tessa and Bois, Haley du and Dulgeroff, Laughing Bear Torrez and Ebadi, Hamid and Espinoza, F. Hernan and Fish, Matt and Gan, Qiang and George, Benson M. and Gillich, Astrid and Green, Foad and Genetiano, Geraldine and Gu, Xueying and Gulati, Gunsagar S. and Hang, Yan and Hosseinzadeh, Shayan and Huang, Albin and Iram, Tal and Isobe, Taichi and Ives, Feather and Jones, Robert and Kao, Kevin S. and Karnam, Guruswamy and Kershner, Aaron M. and Kiss, Bernhard and Kong, William and Kumar, Maya E. and Lam, Jonathan and Lee, Davis P. and Lee, Song E. and Li, Guang and Li, Qingyun and Liu, Ling and Lo, Annie and Lu, Wan-Jin and Manjunath, Anoop and May, Andrew P. and May, Kaia L. and May, Oliver L. and Maynard, Ashley and McKay, Marina and Metzger, Ross J. and Mignardi, Marco and Min, Dullei and Nabhan, Ahmad N. and Neff, Norma F and Ng, Katharine M. and Noh, Joseph and Patkar, Rasika and Peng, Weng Chuan and Penland, Lolita and Puccinelli, Robert and Rulifson, Eric J. and Schaum, Nicholas and Sikandar, Shaheen S. and Sinha, Rahul and Sit, Rene V and Szade, Krzysztof and Tan, Weilun and Tato, Cristina and Tellez, Krissie and Travaglini, Kyle J. and Tropini, Carolina and Waldburger, Lucas and Weele, Linda J. van and Wosczyna, Michael N. and Xiang, Jinyi and Xue, Soso and Youngyunpipatkul, Justin and Zanini, Fabio and Zardeneta, Macy E. and Zhang, Fan and Zhou, Lu and Bansal, Ishita and Chen, Steven and Cho, Min and Cirolia, Giana and Darmanis, Spyros and Demers, Aaron and Divita, Tessa and Ebadi, Hamid and Genetiano, Geraldine and Green, Foad and Hosseinzadeh, Shayan and Ives, Feather and Lo, Annie and May, Andrew P. and Maynard, Ashley and McKay, Marina and Neff, Norma F. and Penland, Lolita and Sit, Rene V. and Tan, Weilun and Waldburger, Lucas and Youngyunpipatkul, Justin and Batson, Joshua and Botvinnik, Olga and Castro, Paola and Croote, Derek and Darmanis, Spyros and DeRisi, Joseph L. and Karkanias, Jim and Pisco, Angela and Stanley, Geoffrey M. and Webber, James T. and Zanini, Fabio and Baghel, Ankit S. and Bakerman, Isaac and Batson, Joshua and Bilen, Biter and Botvinnik, Olga and Brownfield, Douglas and Chen, Michelle B. and Darmanis, Spyros and Demir, Kubilay and Morree, Antoine de and Ebadi, Hamid and Espinoza, F. Hernan and Fish, Matt and Gan, Qiang and George, Benson M. and Gillich, Astrid and Gu, Xueying and Gulati, Gunsagar S. and Hang, Yan and Huang, Albin and Iram, Tal and Isobe, Taichi and Karnam, Guruswamy and Kershner, Aaron M. and Kiss, Bernhard M. and Kong, William and Kuo, Christin S. and Lam, Jonathan and Lehallier, Benoit and Li, Guang and Li, Qingyun and Liu, Ling and Lu, Wan-Jin and Min, Dullei and Nabhan, Ahmad N. and Ng, Katharine M. and Nguyen, Patricia K. and Patkar, Rasika and Peng, Weng Chuan and Penland, Lolita and Rulifson, Eric J. and Schaum, Nicholas and Sikandar, Shaheen S. and Sinha, Rahul and Szade, Krzysztof and Tan, Serena Y. and Tellez, Krissie and Travaglini, Kyle J. and Tropini, Carolina and Weele, Linda J. van and Wang, Bruce M. and Wosczyna, Michael N. and Xiang, Jinyi and Yousef, Hanadie and Zhou, Lu and Batson, Joshua and Botvinnik, Olga and Chen, Steven and Darmanis, Spyros and Green, Foad and May, Andrew P. and Maynard, Ashley and Pisco, Angela and Quake, Stephen R. and Schaum, Nicholas and Stanley, Geoffrey M. and Webber, James T. and Wyss-Coray, Tony and Zanini, Fabio and Beachy, Philip A. and Chan, Charles K. F. and Morree, Antoine de and George, Benson M. and Gulati, Gunsagar S. and Hang, Yan and Huang, Kerwyn Casey and Iram, Tal and Isobe, Taichi and Kershner, Aaron M. and Kiss, Bernhard M. and Kong, William and Li, Guang and Li, Qingyun and Liu, Ling and Lu, Wan-Jin and Nabhan, Ahmad N. and Ng, Katharine M. and Nguyen, Patricia K. and Schaum, Nicholas and Sikandar, Shaheen S. and Sinha, Rahul and Szade, Krzysztof and Travaglini, Kyle J. and Tropini, Carolina and Wang, Bruce M. and Weinberg, Kenneth and Wosczyna, Michael N. and Wu, Sean and Yousef, Hanadie and Barres, Ben A. and Beachy, Philip A. and Chan, Charles K. F. and Clarke, Michael F. and Darmanis, Spyros and Huang, Kerwyn Casey and Karkanias, Jim and Kim, Seung K. and Krasnow, Mark A. and Kuo, Christin S. and May, Andrew P. and Neff, Norma and Nusse, Roel and Nguyen, Patricia K. and Rando, Thomas A. and Sonnenburg, Justin and Wang, Bruce M. and Weinberg, Kenneth and Weissman, Irving L. and Wu, Sean M. and Quake, Stephen R. and Wyss-Coray, Tony},
	title = {Single-cell transcriptomic characterization of 20 organs and tissues from individual mice creates a Tabula Muris},
	elocation-id = {237446},
	year = {2018},
	doi = {10.1101/237446},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {We have created a compendium of single cell transcriptome data from the model organism Mus musculus comprising more than 100,000 cells from 20 organs and tissues. These data represent a new resource for cell biology, revealing gene expression in poorly characterized cell populations and allowing for direct and controlled comparison of gene expression in cell types shared between tissues, such as T-lymphocytes and endothelial cells from distinct anatomical locations. Two distinct technical approaches were used for most tissues: one approach, microfluidic droplet-based 3{\textquoteright}-end counting, enabled the survey of thousands of cells at relatively low coverage, while the other, FACS-based full length transcript analysis, enabled characterization of cell types with high sensitivity and coverage. The cumulative data provide the foundation for an atlas of transcriptomic cell biology.},
	URL = {https://www.biorxiv.org/content/early/2018/03/29/237446},
	eprint = {https://www.biorxiv.org/content/early/2018/03/29/237446.full.pdf},
	journal = {bioRxiv}
}


@misc{unbsinkhorn,
      title={Faster Unbalanced Optimal Transport: Translation invariant Sinkhorn and 1-D Frank-Wolfe}, 
      author={Thibault Séjourné and François-Xavier Vialard and Gabriel Peyré},
      year={2022},
      eprint={2201.00730},
      archivePrefix={arXiv},
      primaryClass={math.OC},
      url={https://arxiv.org/abs/2201.00730}, 
}
@inproceedings{fast_sh,
 author = {Chizat, L\'{e}na\"{\i}c and Roussillon, Pierre and L\'{e}ger, Flavien and Vialard, Fran\c{c}ois-Xavier and Peyr\'{e}, Gabriel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {2257--2269},
 publisher = {Curran Associates, Inc.},
 title = {Faster Wasserstein Distance Estimation with the Sinkhorn Divergence},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/17f98ddf040204eda0af36a108cbdea4-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{ari,
  author = {Hubert, L. and Arabie, P.},
  journal = {Journal of classification},
  keywords = {adjusted ari clustering evaluation index rand},
  number = {1},
  pages = {193--218},
  publisher = {Springer},
  timestamp = {2009-08-17T10:11:23.000+0200},
  title = {{Comparing partitions}},
  url = {http://scholar.google.de/scholar.bib?q=info:IkrWWF2JxwoJ:scholar.google.com/&output=citation&hl=de&ct=citation&cd=0},
  volume = {2},
  year = {1985}
}

@article{ami,
  author  = {Nguyen Xuan Vinh and Julien Epps and James Bailey},
  title   = {Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance},
  journal = {Journal of Machine Learning Research},
  year    = {2010},
  volume  = {11},
  number  = {95},
  pages   = {2837--2854},
  url     = {http://jmlr.org/papers/v11/vinh10a.html}
}

@article{Chakraborty:2023, 
year = {2023}, 
title = {{Robust probabilistic inference via a constrained transport metric}}, 
author = {Chakraborty, Abhisek and Bhattacharya, Anirban and Pati, Debdeep}, 
journal = {arXiv}, 
eprint = {2303.10085}, 
}


@article{Dewaskar:2023, 
year = {2023}, 
title = {{Robustifying likelihoods by optimistically re-weighting data}}, 
author = {Dewaskar, Miheer and Tosh, Christopher and Knoblauch, Jeremias and Dunson, David B}, 
journal = {arXiv}, 
eprint = {2303.10525}, 
}


@article{Wu:2024, 
year = {2024}, 
title = {{Adaptive Nonparametric Perturbations of Parametric Bayesian Models}}, 
author = {Wu, Bohan and Weinstein, Eli N and Salehi, Sohrab and Wang, Yixin and Blei, David M}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2412.10683}, 
eprint = {2412.10683}, 
}


@article{Xue:2024,
year = {2024}, 
title = {{Robust discovery of mutational signatures using power posteriors}}, 
author = {Xue, Catherine and Miller, Jeffrey W. and Carter, Scott L. and Huggins, Jonathan H.}, 
journal = {bioRxiv}, 
doi = {10.1101/2024.10.23.619958}, 
pages = {2024.10.23.619958}, 
}


@article{Zito:2024,
year = {2024}, 
title = {{Compressive Bayesian non-negative matrix factorization for mutational signatures analysis}}, 
author = {Zito, Alessandro and Miller, Jeffrey W}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2404.10974}, 
eprint = {2404.10974}, 
}

@article{Jewson_2018,
	doi = {10.3390/e20060442},
	url = {https://doi.org/10.3390%2Fe20060442},
	year = 2018,
	month = {jun},
	publisher = {{MDPI} {AG}
},
  
	volume = {20},
	number = {6},
	pages = {442},
	author = {Jack Jewson and Jim Smith and Chris Holmes},
	title = {Principles of Bayesian Inference Using General Divergence Criteria},
	journal = {Entropy}
}

@inproceedings{Cho-Jui_greedycd_2011,
author = {Hsieh, Cho-Jui and Dhillon, Inderjit S.},
title = {Fast coordinate descent methods with variable selection for non-negative matrix factorization},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020577},
doi = {10.1145/2020408.2020577},
abstract = {Nonnegative Matrix Factorization (NMF) is an effective dimension reduction method for non-negative dyadic data, and has proven to be useful in many areas, such as text mining, bioinformatics and image processing. NMF is usually formulated as a constrained non-convex optimization problem, and many algorithms have been developed for solving it. Recently, a coordinate descent method, called FastHals, has been proposed to solve least squares NMF and is regarded as one of the state-of-the-art techniques for the problem. In this paper, we first show that FastHals has an inefficiency in that it uses a cyclic coordinate descent scheme and thus, performs unneeded descent steps on unimportant variables. We then present a variable selection scheme that uses the gradient of the objective function to arrive at a new coordinate descent method. Our new method is considerably faster in practice and we show that it has theoretical convergence guarantees. Moreover when the solution is sparse, as is often the case in real applications, our new method benefits by selecting important variables to update more often, thus resulting in higher speed. As an example, on a text dataset RCV1, our method is 7 times faster than FastHals, and more than 15 times faster when the sparsity is increased by adding an L1 penalty. We also develop new coordinate descent methods when error in NMF is measured by KL-divergence by applying the Newton method to solve the one-variable sub-problems. Experiments indicate that our algorithm for minimizing the KL-divergence is faster than the Lee \& Seung multiplicative rule by a factor of 10 on the CBCL image dataset.},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1064–1072},
numpages = {9},
keywords = {non-negative matrix factorization, coordinate descent method, convergence},
location = {San Diego, California, USA},
series = {KDD '11}
}

@article{Miao-Qi_mvc_2007,
  title = {Endmember {{Extraction From Highly Mixed Data Using Minimum Volume Constrained Nonnegative Matrix Factorization}}},
  author = {Miao, Lidan and Qi, Hairong},
  year = {2007},
  month = mar,
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {45},
  number = {3},
  pages = {765--777},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2006.888466},
  urldate = {2024-08-06},
  abstract = {Endmember extraction is a process to identify the hidden pure source signals from the mixture. In the past decade, numerous algorithms have been proposed to perform this estimation. One commonly used assumption is the presence of pure pixels in the given image scene, which are detected to serve as endmembers. When such pixels are absent, the image is referred to as the highly mixed data, for which these algorithms at best can only return certain data points that are close to the real endmembers. To overcome this problem, we present a novel method without the pure-pixel assumption, referred to as the minimum volume constrained nonnegative matrix factorization (MVC-NMF), for unsupervised endmember extraction from highly mixed image data. Two important facts are exploited: First, the spectral data are nonnegative; second, the simplex volume determined by the endmembers is the minimum among all possible simplexes that circumscribe the data scatter space. The proposed method takes advantage of the fast convergence of NMF schemes, and at the same time eliminates the pure-pixel assumption. The experimental results based on a set of synthetic mixtures and a real image scene demonstrate that the proposed method outperforms several other advanced endmember detection approaches},
  keywords = {Clouds,Convex geometry,Data mining,endmember,Geometry,Hyperspectral imaging,Hyperspectral sensors,Independent component analysis,Layout,nonnegative matrix factorization (NMF),Pixel,Principal component analysis,Signal processing,simplex,spectral unmixing},
  file = {/home/nguyenston/Zotero/storage/RPFUNHKM/Miao and Qi - 2007 - Endmember Extraction From Highly Mixed Data Using Minimum Volume Constrained Nonnegative Matrix Fact.pdf}
}

@article{Cichocki-Phan_coorddesc_2009,
  title = {Fast {{Local Algorithms}} for {{Large Scale Nonnegative Matrix}} and {{Tensor Factorizations}}},
  author = {Cichocki, Andrzej and Phan, Anh-Huy},
  year = {2009},
  month = mar,
  journal = {IEICE Transactions},
  volume = {92-A},
  pages = {708--721},
  doi = {10.1587/transfun.E92.A.708},
  abstract = {Nonnegative matrix factorization (NMF) and its extensions such as Nonnegative Tensor Factorization (NTF) have become prominent techniques for blind sources separation (BSS), analysis of image databases, data mining and other information retrieval and clustering applications. In this paper we propose a family of efficient algorithms for NMF/NTF, as well as sparse nonnegative coding and representation, that has many potential applications in computational neuroscience, multi-sensory processing, compressed sensing and multidimensional data analysis. We have developed a class of optimized local algorithms which are referred to as Hierarchical Alternating Least Squares (HALS) algorithms. For these purposes, we have performed sequential constrained minimization on a set of squared Euclidean distances. We then extend this approach to robust cost functions using the alpha and beta divergences and derive flexible update rules. Our algorithms are locally stable and work well for NMF-based blind source separation (BSS) not only for the over-determined case but also for an under-determined (over-complete) case (i.e., for a system which has less sensors than sources) if data are sufficiently sparse. The NMF learning rules are extended and generalized for N-th order nonnegative tensor factorization (NTF). Moreover, these algorithms can be tuned to different noise statistics by adjusting a single parameter. Extensive experimental results confirm the accuracy and computational performance of the developed algorithms, especially, with usage of multi-layer hierarchical NMF approach [3].},
  file = {/home/nguyenston/Zotero/storage/SA4M74I7/Cichocki and Phan - 2009 - Fast Local Algorithms for Large Scale Nonnegative Matrix and Tensor Factorizations.pdf}
}

@article{Pelizzola_NegBin-NMF_2023,
  title = {Model Selection and Robust Inference of Mutational Signatures Using {{Negative Binomial}} Non-Negative Matrix Factorization},
  author = {Pelizzola, Marta and Laursen, Ragnhild and Hobolth, Asger},
  year = {2023},
  month = may,
  journal = {BMC Bioinformatics},
  volume = {24},
  number = {1},
  pages = {187},
  issn = {1471-2105},
  doi = {10.1186/s12859-023-05304-1},
  urldate = {2024-01-28},
  abstract = {The spectrum of mutations in a collection of cancer genomes can be described by a mixture of a few mutational signatures. The mutational signatures can be found using non-negative matrix factorization (NMF). To extract the mutational signatures we have to assume a distribution for the observed mutational counts and a number of mutational signatures. In most applications, the mutational counts are assumed to be Poisson distributed, and the rank is chosen by comparing the fit of several models with the same underlying distribution and different values for the rank using classical model selection procedures. However, the counts are often overdispersed, and thus the Negative Binomial distribution is more appropriate.},
  keywords = {62-08,92-08,92-10,bayesMixture,Cancer genomics,Cross-validation,Model checking,Model selection,Mutational signatures,Negative Binomial,Non-negative matrix factorization,Poisson},
  file = {/home/nguyenston/Zotero/storage/UV76NHA4/Pelizzola et al. - 2023 - Model selection and robust inference of mutational.pdf;/home/nguyenston/Zotero/storage/6BSN48NL/s12859-023-05304-1.html}
}

@inproceedings{Liu_Support-Union_2019,
  title = {Model {{Selection}} for {{Nonnegative Matrix Factorization}} by {{Support Union Recovery}}},
  booktitle = {{{ICASSP}} 2019 - 2019 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Liu, Zhaoqiang},
  year = {2019},
  month = may,
  pages = {3407--3411},
  issn = {2379-190X},
  doi = {10.1109/ICASSP.2019.8683718},
  urldate = {2024-08-20},
  abstract = {Nonnegative matrix factorization (NMF) has been widely used in machine learning and signal processing because of its non-subtractive, part-based property which enhances interpretability. It is often assumed that the latent dimensionality (or the number of components) is given. Despite the large amount of algorithms designed for NMF, there is little literature about automatic model selection for NMF with theoretical guarantees. In this paper, we propose an algorithm that first calculates an empirical second-order moment from the empirical fourth-order cumulant tensor, and then estimates the latent dimensionality by recovering the support union (the index set of non-zero rows) of a matrix related to the empirical second-order moment. By assuming a generative model of the data with additional mild conditions, our algorithm provably detects the true latent dimensionality. We show on synthetic examples that our proposed algorithm is able to find approximately correct number of components.},
  keywords = {Model selection,Multiple measurement vector,Nonnegative matrix factorization,Support union recovery,Tensor method},
  file = {/home/nguyenston/Zotero/storage/V5VH2IYC/Liu - 2019 - Model Selection for Nonnegative Matrix Factorization by Support Union Recovery.pdf}
}

@misc{Li_Stare-Mixture_2024,
      title={Structurally Aware Robust Model Selection for Mixtures}, 
      author={Jiawei Li and Jonathan H. Huggins},
      year={2024},
      eprint={2403.00687},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2403.00687}, 
}

@article{Hubert_ARI_1985,
  title={Comparing partitions},
  author={Lawrence J. Hubert and Phipps Arabie},
  journal={Journal of Classification},
  year={1985},
  volume={2},
  pages={193-218},
  url={https://api.semanticscholar.org/CorpusID:189915041}
}

@article{Flynt_sARI_2019,
  title = {{{sARI}}: A Soft Agreement Measure for Class Partitions Incorporating Assignment Probabilities},
  shorttitle = {{{sARI}}},
  author = {Flynt, Abby and Dean, Nema and Nugent, Rebecca},
  year = {2019},
  month = mar,
  journal = {Advances in Data Analysis and Classification},
  volume = {13},
  number = {1},
  pages = {303--323},
  issn = {1862-5355},
  doi = {10.1007/s11634-018-0346-x},
  urldate = {2024-09-06},
  abstract = {Agreement indices are commonly used to summarize the performance of both classification and clustering methods. The easy interpretation/intuition and desirable properties that result from the Rand and adjusted Rand indices, has led to their popularity over other available indices. While more algorithmic clustering approaches like k-means and hierarchical clustering produce hard partition assignments (assigning observations to a single cluster), other techniques like model-based clustering include information about the certainty of allocation of objects through class membership probabilities (soft partitions). To assess performance using traditional indices, e.g., the adjusted Rand index (ARI), the soft partition is mapped to a hard set of assignments, which commonly overstates the certainty of correct assignments. This paper proposes an extension of the ARI, the soft adjusted Rand index (sARI), with similar intuition and interpretation but also incorporating information from one or two soft partitions. It can be used in conjunction with the ARI, comparing the similarities of hard to soft, or soft to soft partitions to the similarities of the mapped hard partitions. Simulation study results support the intuition that in general, mapping to hard partitions tends to increase the measure of similarity between partitions. In applications, the sARI more accurately reflects the cluster boundary overlap commonly seen in real data.},
  langid = {english},
  keywords = {62H30,62H86,91C20,Adjusted Rand index,Class membership probabilities,Mixture models,Model-based clustering,Posterior probabilities,Soft partition},
  file = {/home/nguyenston/Zotero/storage/8ISD4JXG/Flynt et al. - 2019 - sARI a soft agreement measure for class partitions incorporating assignment probabilities.pdf}
}

@incollection{Joyce_KL-Divergence_2011,
  title = {Kullback-Leibler Divergence},
  booktitle = {International Encyclopedia of Statistical Science},
  author = {Joyce, James M.},
  editor = {Lovric, Miodrag},
  year = {2011},
  pages = {720--722},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-04898-2_327},
  isbn = {978-3-642-04898-2}
}

@misc{Sriperumbudur_HilbertSpaceEmbeddings_2010,
  title = {Hilbert Space Embeddings and Metrics on Probability Measures},
  author = {Sriperumbudur, Bharath K. and Gretton, Arthur and Fukumizu, Kenji and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert R. G.},
  year = {2010},
  month = jan,
  number = {arXiv:0907.5309},
  eprint = {0907.5309},
  primaryclass = {math, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.0907.5309},
  urldate = {2024-09-25},
  abstract = {A Hilbert space embedding for probability measures has recently been proposed, with applications including dimensionality reduction, homogeneity testing, and independence testing. This embedding represents any probability measure as a mean element in a reproducing kernel Hilbert space (RKHS). A pseudometric on the space of probability measures can be defined as the distance between distribution embeddings: we denote this as \${\textbackslash}gamma\_k\$, indexed by the kernel function \$k\$ that defines the inner product in the RKHS. We present three theoretical properties of \${\textbackslash}gamma\_k\$. First, we consider the question of determining the conditions on the kernel \$k\$ for which \${\textbackslash}gamma\_k\$ is a metric: such \$k\$ are denoted \{{\textbackslash}em characteristic kernels\}. Unlike pseudometrics, a metric is zero only when two distributions coincide, thus ensuring the RKHS embedding maps all distributions uniquely (i.e., the embedding is injective). While previously published conditions may apply only in restricted circumstances (e.g. on compact domains), and are difficult to check, our conditions are straightforward and intuitive: bounded continuous strictly positive definite kernels are characteristic. Alternatively, if a bounded continuous kernel is translation-invariant on \${\textbackslash}bb\{R\}{\textasciicircum}d\$, then it is characteristic if and only if the support of its Fourier transform is the entire \${\textbackslash}bb\{R\}{\textasciicircum}d\$. Second, we show that there exist distinct distributions that are arbitrarily close in \${\textbackslash}gamma\_k\$. Third, to understand the nature of the topology induced by \${\textbackslash}gamma\_k\$, we relate \${\textbackslash}gamma\_k\$ to other popular metrics on probability measures, and present conditions on the kernel \$k\$ under which \${\textbackslash}gamma\_k\$ metrizes the weak topology.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/home/nguyenston/Zotero/storage/DWNNSLRX/Sriperumbudur et al. - 2010 - Hilbert space embeddings and metrics on probability measures.pdf;/home/nguyenston/Zotero/storage/CVEJSZXR/0907.html}
}

@misc{Gibbs_Hellinger-distance_2002,
  title={On choosing and bounding probability metrics}, 
  author={Alison L. Gibbs and Francis Edward Su},
  year={2002},
  eprint={math/0209021},
  archivePrefix={arXiv},
  primaryClass={math.PR},
  url={https://arxiv.org/abs/math/0209021}, 
}

@inbook{Villani_OptimalTransport_2008,
  author = {Villani, Cédric},
  year = {2008},
  month = {01},
  pages = {xxii+973},
  title = {Optimal transport -- Old and new},
  volume = {338},
  doi = {10.1007/978-3-540-71050-9}
}

@inproceedings{Lee-Seung_multdiv_2000,
  author = {Lee, Daniel and Seung, H. Sebastian},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {T. Leen and T. Dietterich and V. Tresp},
  pages = {},
  publisher = {MIT Press},
  title = {Algorithms for Non-negative Matrix Factorization},
  url = {https://proceedings.neurips.cc/paper_files/paper/2000/file/f9d1152547c0bde01830b7e8bd60024c-Paper.pdf},
  volume = {13},
  year = {2000}
}

@article{Alexandrov_mut-sig-NMF_2013,
  title = {Deciphering {{Signatures}} of {{Mutational Processes Operative}} in {{Human Cancer}}},
  author = {Alexandrov, Ludmil B. and {Nik-Zainal}, Serena and Wedge, David C. and Campbell, Peter J. and Stratton, Michael R.},
  year = {2013},
  month = jan,
  journal = {Cell Reports},
  volume = {3},
  number = {1},
  pages = {246},
  doi = {10.1016/j.celrep.2012.12.008},
  urldate = {2024-11-12},
  abstract = {The genome of a cancer cell carries somatic mutations that are the cumulative consequences of the DNA damage and repair processes operative during the cellular lineage between the fertilized egg and the cancer cell. Remarkably, these mutational ...},
  langid = {english},
  pmid = {23318258},
  file = {/home/nguyenston/Zotero/storage/N9AR4CBH/Alexandrov et al. - 2013 - Deciphering Signatures of Mutational Processes Operative in Human Cancer.pdf}
}

@article{Berry_Alg-and-App-for-NMF_2007,
  title = {Algorithms and Applications for Approximate Nonnegative Matrix Factorization},
  author = {Berry, Michael W. and Browne, Murray and Langville, Amy N. and Pauca, V. Paul and Plemmons, Robert J.},
  year = {2007},
  month = sep,
  journal = {Computational Statistics \& Data Analysis},
  volume = {52},
  number = {1},
  pages = {155--173},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2006.11.006},
  urldate = {2024-11-12},
  abstract = {The development and use of low-rank approximate nonnegative matrix factorization (NMF) algorithms for feature extraction and identification in the fields of text mining and spectral data analysis are presented. The evolution and convergence properties of hybrid methods based on both sparsity and smoothness constraints for the resulting nonnegative matrix factors are discussed. The interpretability of NMF outputs in specific contexts are provided along with opportunities for future work in the modification of NMF algorithms for large-scale and time-varying data sets.},
  keywords = {Conjugate gradient,Constrained least squares,Email surveillance,Nonnegative matrix factorization,Spectral data analysis,Text mining},
  file = {/home/nguyenston/Zotero/storage/6KMLU9SS/S0167947306004191.html}
}

@misc{Zheng_rSVD-recommender_2018,
  title = {Regularized {{Singular Value Decomposition}} and {{Application}} to {{Recommender System}}},
  author = {Zheng, Shuai and Ding, Chris and Nie, Feiping},
  year = {2018},
  month = apr,
  number = {arXiv:1804.05090},
  eprint = {1804.05090},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1804.05090},
  urldate = {2024-11-12},
  abstract = {Singular value decomposition (SVD) is the mathematical basis of principal component analysis (PCA). Together, SVD and PCA are one of the most widely used mathematical formalism/decomposition in machine learning, data mining, pattern recognition, artificial intelligence, computer vision, signal processing, etc. In recent applications, regularization becomes an increasing trend. In this paper, we present a regularized SVD (RSVD), present an efficient computational algorithm, and provide several theoretical analysis. We show that although RSVD is non-convex, it has a closed-form global optimal solution. Finally, we apply RSVD to the application of recommender system and experimental result show that RSVD outperforms SVD significantly.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/nguyenston/Zotero/storage/LNSF9UII/Zheng et al. - 2018 - Regularized Singular Value Decomposition and Application to Recommender System.pdf;/home/nguyenston/Zotero/storage/A2ZA2RX5/1804.html}
}

@misc{Xue_Bayes-NMF_2024,
  title = {Robust Discovery of Mutational Signatures Using Power Posteriors},
  author = {Xue, Catherine and Miller, Jeffrey W. and Carter, Scott L. and Huggins, Jonathan H.},
  year = {2024},
  month = oct,
  primaryclass = {New Results},
  pages = {2024.10.23.619958},
  publisher = {bioRxiv},
  doi = {10.1101/2024.10.23.619958},
  urldate = {2024-11-13},
  abstract = {Mutational processes, such as the molecular effects of carcinogenic agents or defective DNA repair mechanisms, are known to produce different mutation types with characteristic frequency profiles, referred to as mutational signatures. Non-negative matrix factorization (NMF) has successfully been used to discover many mutational signatures, yielding novel insights into cancer etiology and targeted therapies. However, the NMF model is only a rough approximation to reality, and even small departures from this assumed model can have large negative effects on the accuracy and reliability of the results. We propose a new approach to mutational signatures analysis that improves robustness to misspecification by using a power posterior for a fully Bayesian NMF model, while employing a sparsity-inducing prior to automatically infer the number of active signatures. In extensive simulation studies, we find that our proposed approach recovers more true signatures with greater accuracy than current leading methods. On whole-genome sequencing data for six cancer types from the ICGC/TCGA Pan-Cancer Analysis of Whole Genomes Consortium, we find that our method is able to accurately recover more signatures than the current state-of-the-art.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english}
}

@misc{Hung_GIC-PCA_2020,
  title={A generalized information criterion for high-dimensional PCA rank selection}, 
  author={Hung Hung and Su-Yun Huang and Ching-Kang Ing},
  year={2020},
  eprint={2004.13914},
  archivePrefix={arXiv},
  primaryClass={stat.ME},
  url={https://arxiv.org/abs/2004.13914}, 
}

@article{Horn_ParallelAnalysis_1965,
  title = {A Rationale and Test for the Number of Factors in Factor Analysis},
  author = {Horn, John L.},
  year = {1965},
  month = jun,
  journal = {Psychometrika},
  volume = {30},
  number = {2},
  pages = {179--185},
  issn = {1860-0980},
  doi = {10.1007/BF02289447},
  urldate = {2025-01-13},
  abstract = {It is suggested that if Guttman's latent-root-one lower bound estimate for the rank of a correlation matrix is accepted as a psychometric upper bound, following the proofs and arguments of Kaiser and Dickman, then the rank for a sample matrix should be estimated by subtracting out the component in the latent roots which can be attributed to sampling error, and least-squares ``capitalization'' on this error, in the calculation of the correlations and the roots. A procedure based on the generation of random variables is given for estimating the component which needs to be subtracted.},
  langid = {english},
  keywords = {Correlation Matrix,Latent Root,Public Policy,Sampling Error,Statistical Theory}
}

@article{Buja_RemarksParallelAnalysis_1992,
  title = {Remarks on {{Parallel Analysis}}},
  author = {Buja, A. and Eyuboglu, N.},
  year = {1992},
  month = oct,
  journal = {Multivariate Behavioral Research},
  volume = {27},
  number = {4},
  pages = {509--540},
  issn = {0027-3171},
  doi = {10.1207/s15327906mbr2704_2},
  abstract = {We investigate parallel analysis (PA), a selection rule for the number-of-factors problem, from the point of view of permutation assessment. The idea of applying permutation test ideas to PA leads to a quasi-inferential, non-parametric version of PA which accounts not only for finite-sample bias but sampling variability as well. We give evidence, however, that quasi-inferential PA based on normal random variates (as opposed to data permutations) is surprisingly independent of distributional assumptions, and enjoys therefore certain non- parametric properties as well. This is a justification for providing tables for quasi-inferential PA. Based on permutation theory, we compare PA of principal components with PA of principal factor analysis and show that PA of principal factors may tend to select too many factors. We also apply parallel analysis to so-called resistant correlations and give evidence that this yields a slightly more conservative factor selection method. Finally, we apply PA to loadings and show how this provides benchmark values for loadings which are sensitive to the number of variables, number of subjects, and order of factors. These values therefore improve on conventional fixed thresholds such as 0.5 or 0.8 which are used irrespective of the size of the data.},
  langid = {english},
  pmid = {26811132}
}

@article{Dobriban_PA-for-FA_2020,
  title = {Permutation Methods for Factor Analysis and {{PCA}}},
  author = {Dobriban, Edgar},
  year = {2020},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {48},
  number = {5},
  issn = {0090-5364},
  doi = {10.1214/19-AOS1907},
  urldate = {2024-04-09},
  langid = {english},
  keywords = {bayesMixture},
  file = {/home/nguyenston/Zotero/storage/588E98WW/Dobriban - 2020 - Permutation methods for factor analysis and PCA.pdf}
}

@article{Zwick_ComparisonFiveRules_1986,
  title = {Comparison of Five Rules for Determining the Number of Components to Retain},
  author = {Zwick, William R. and Velicer, Wayne F.},
  year = {1986},
  journal = {Psychological Bulletin},
  volume = {99},
  number = {3},
  pages = {432--442},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.99.3.432},
  abstract = {Investigated the performance of 5 methods for determining the number of components to retain---J. L. Horn's (see record 1965-13273-001) parallel analysis, W. F. Velicer's (see record 1977-00166-001) minimum average partial (MAP), R. B. Cattell's (see PA, Vol 41:969) scree test, M. S. Bartlett's (1950) chi-square test, and H. F. Kaiser's (see record 1960-06772-001) eigenvalue greater than 1 rule---across 7 systematically varied conditions (sample size, number of variables, number of components, component saturation, equal or unequal numbers of variables for each component, and the presence or absence of unique and complex variables). Five sample correlation matrices were generated at each of 2 sample sizes from the 48 known population correlation matrices representing 6 levels of component pattern complexity. Results indicate that the performance of the parallel analysis and MAP methods was generally the best across all situations; the scree test was generally accurate but variable; and Bartlett's chi-square test was less accurate and more variable than the scree test. Kaiser's method tended to severely overestimate the number of components. (65 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Factor Analysis,Statistical Correlation},
  file = {/home/nguyenston/Zotero/storage/Z2JYRY9M/Zwick and Velicer - Comparison of Five Rules for Determining the Number of Components to Retain.pdf;/home/nguyenston/Zotero/storage/EREYJQLI/1986-21041-001.html}
}

@article{Velicer_MAP_1976,
  title = {Determining the Number of Components from the Matrix of Partial Correlations},
  author = {Velicer, Wayne F.},
  year = {1976},
  month = sep,
  journal = {Psychometrika},
  volume = {41},
  number = {3},
  pages = {321--327},
  publisher = {Springer-Verlag},
  issn = {1860-0980},
  doi = {10.1007/BF02293557},
  urldate = {2025-02-03},
  abstract = {A common problem for both principal component analysis and image component analysis is determining how many components to retain. A number of solutions have been proposed, none of which is totally satisfactory. An alternative solution which employs a matrix of partial correlations is considered. No components are extracted after the average squared partial correlation reaches a minimum. This approach gives an exact stopping point, has a direct operational interpretation, and can be applied to any type of component analysis. The method is most appropriate when component analysis is employed as an alternative to, or a first-stage solution for, factor analysis.},
  copyright = {1976 Psychometric Society},
  langid = {english}
}

@article{Tran_Performance-PA-Binary_2009,
  title = {Performance of {{Parallel Analysis}} in {{Retrieving Unidimensionality}} in the {{Presence}} of {{Binary Data}}},
  author = {Tran, Ulrich S. and Formann, Anton K.},
  year = {2009},
  month = feb,
  journal = {Educational and Psychological Measurement},
  volume = {69},
  number = {1},
  pages = {50--61},
  publisher = {SAGE Publications Inc},
  issn = {0013-1644},
  doi = {10.1177/0013164408318761},
  urldate = {2025-01-30},
  abstract = {Parallel analysis has been shown to be suitable for dimensionality assessment in factor analysis of continuous variables. There have also been attempts to demonstrate that it may be used to uncover the factorial structure of binary variables conforming to the unidimensional normal ogive model. This article provides both theoretical and empirical evidence that this is not appropriate. Results of a simulation study indicate that sample size, item discrimination, and type of correlation coefficient (Pearson vs. tetrachoric correlation) considerably influence the performance of parallel analysis. Reliability of parallel analysis with binary variables is found to be notably poor for Pearson correlations and also limited for tetrachoric correlations.},
  langid = {english},
  file = {/home/nguyenston/Zotero/storage/MDC29BQT/Tran and Formann - 2009 - Performance of Parallel Analysis in Retrieving Unidimensionality in the Presence of Binary Data.pdf}
}

@article{Warne_Evaluating-PA-MAP_2014,
  title = {Evaluating a Proposed Modification of the {{Guttman}} Rule for Determining the Number of Factors in an Exploratory Factor Analysis},
  author = {Warne, Russell and Larsen, Ross},
  year = {2014},
  month = mar,
  journal = {Psychol. Test Assess. Model.},
  volume = {56},
  pages = {104--123},
  abstract = {Exploratory factor analysis (EFA) is a widely used statistical method in which researchers attempt to ascertain the number and nature of latent factors that explain their observed variables. When conducting an EFA, researchers must choose the number of factors to retain -- a critical decision that has drastic effects if made incorrectly. In this article, we examine a newly proposed method of choosing the number of factors to retain. In the new method, confidence intervals are created around each eigenvalue and factors are retained if the entire eigenvalue is greater than 1.0. Results show that this new method outperforms the traditional Guttman rule, but does not surpass the accuracy of Velicer's minimum average partial (MAP) or Horn's parallel analysis (PA). MAP was the most accurate method overall, although it had a tendency to underfactor in some conditions. PA was the second most accurate method, although it frequently overfactored. PA was also found to be sensitive to sample size and MAP was found to occasionally grossly overfactor; these findings had not previously been reported in the literature.},
  file = {/home/nguyenston/Zotero/storage/8YBUJVR8/Warne and Larsen - 2014 - Evaluating a proposed modification of the Guttman rule for determining the number of factors in an e.pdf}
}

@article{Garrido_Performance-MAP-Categorical_2011,
  title = {Performance of {{Velicer}}'s {{Minimum Average Partial Factor Retention Method With Categorical Variables}}},
  author = {Garrido, Luis and Abad, Francisco and Ponsoda, Vicente},
  year = {2011},
  month = may,
  journal = {Educational and Psychological Measurement - EDUC PSYCHOL MEAS},
  volume = {71},
  pages = {551--570},
  doi = {10.1177/0013164410389489},
  abstract = {Despite strong evidence supporting the use of Velicer's minimum average partial (MAP) method to establish the dimensionality of continuous variables, little is known about its performance with categorical data. Seeking to fill this void, the current study takes an in-depth look at the performance of the MAP procedure in the presence of ordinal-level measurement. Using Monte Carlo methods, seven factors related to the data (sample size, factor loading, number of variables per factor, number of factors, factor correlation, number of response categories, and skewness) as well as two factors related to the MAP method (type of correlation matrix and power) were systematically manipulated. The results indicate that using polychoric correlations and the squared partial correlations leads to considerably more accurate estimations than using Pearson correlations and/or raising the partial correlations to the fourth power. Additionally, the MAP method is shown to be a biased estimator of dimensionality in two conditions: (a) for low factor loadings (.40) and (b) for medium factor loadings (.55) and a small number of variables per factor ({$\leq$} 6). The applicability of this method with categorical variables is discussed in the context of these findings.},
  file = {/home/nguyenston/Zotero/storage/75X96T9B/Garrido et al. - 2011 - Performance of Velicer’s Minimum Average Partial Factor Retention Method With Categorical Variables.pdf}
}

@article{Nik-zainal_MutationalProcessesMolding_2012,
  title = {Mutational Processes Molding the Genomes of 21 Breast Cancers},
  author = {{Nik-Zainal}, Serena and Alexandrov, Ludmil B. and Wedge, David C. and Van Loo, Peter and Greenman, Christopher D. and Raine, Keiran and Jones, David and Hinton, Jonathan and Marshall, John and Stebbings, Lucy A. and Menzies, Andrew and Martin, Sancha and Leung, Kenric and Chen, Lina and Leroy, Catherine and Ramakrishna, Manasa and Rance, Richard and Lau, King Wai and Mudie, Laura J. and Varela, Ignacio and McBride, David J. and Bignell, Graham R. and Cooke, Susanna L. and Shlien, Adam and Gamble, John and Whitmore, Ian and Maddison, Mark and Tarpey, Patrick S. and Davies, Helen R. and Papaemmanuil, Elli and Stephens, Philip J. and McLaren, Stuart and Butler, Adam P. and Teague, Jon W. and J{\"o}nsson, G{\"o}ran and Garber, Judy E. and Silver, Daniel and Miron, Penelope and Fatima, Aquila and Boyault, Sandrine and Langer{\o}d, Anita and Tutt, Andrew and Martens, John W. M. and Aparicio, Samuel A. J. R. and Borg, {\AA}ke and Salomon, Anne Vincent and Thomas, Gilles and {B{\o}rresen-Dale}, Anne-Lise and Richardson, Andrea L. and Neuberger, Michael S. and Futreal, P. Andrew and Campbell, Peter J. and Stratton, Michael R. and {Breast Cancer Working Group of the International Cancer Genome Consortium}},
  year = {2012},
  month = may,
  journal = {Cell},
  volume = {149},
  number = {5},
  pages = {979--993},
  issn = {1097-4172},
  doi = {10.1016/j.cell.2012.04.024},
  abstract = {All cancers carry somatic mutations. The patterns of mutation in cancer genomes reflect the DNA damage and repair processes to which cancer cells and their precursors have been exposed. To explore these mechanisms further, we generated catalogs of somatic mutation from 21 breast cancers and applied mathematical methods to extract mutational signatures of the underlying processes. Multiple distinct single- and double-nucleotide substitution signatures were discernible. Cancers with BRCA1 or BRCA2 mutations exhibited a characteristic combination of substitution mutation signatures and a distinctive profile of deletions. Complex relationships between somatic mutation prevalence and transcription were detected. A remarkable phenomenon of localized hypermutation, termed "kataegis," was observed. Regions of kataegis differed between cancers but usually colocalized with somatic rearrangements. Base substitutions in these regions were almost exclusively of cytosine at TpC dinucleotides. The mechanisms underlying most of these mutational signatures are unknown. However, a role for the APOBEC family of cytidine deaminases is proposed.},
  langid = {english},
  pmcid = {PMC3414841},
  pmid = {22608084},
  keywords = {APOBEC-1 Deaminase,BRCA2 Protein,Breast Neoplasms,Cytidine Deaminase,DNA Mutational Analysis,Female,Genes BRCA1,Genome-Wide Association Study,High-Throughput Nucleotide Sequencing,Humans,Mutation},
  file = {/home/nguyenston/Zotero/storage/XHQHPI7C/Nik-Zainal et al. - 2012 - Mutational processes molding the genomes of 21 breast cancers.pdf}
}

@article{Kotliar_Identify_Cell_Idendity_Activity_NMF_2019,
  title = {Identifying Gene Expression Programs of Cell-Type Identity and Cellular Activity with Single-Cell {{RNA-Seq}}},
  author = {Kotliar, Dylan and Veres, Adrian and Nagy, M Aurel and Tabrizi, Shervin and Hodis, Eran and Melton, Douglas A and Sabeti, Pardis C},
  year = {2019},
  journal = {eLife},
  volume = {8},
  pages = {e43803},
  issn = {2050-084X},
  doi = {10.7554/eLife.43803},
  urldate = {2025-04-17},
  abstract = {Identifying gene expression programs underlying both cell-type identity and cellular activities (e.g. life-cycle processes, responses to environmental cues) is crucial for understanding the organization of cells and tissues. Although single-cell RNA-Seq (scRNA-Seq) can quantify transcripts in individual cells, each cell's expression profile may be a mixture of both types of programs, making them difficult to disentangle. Here, we benchmark and enhance the use of matrix factorization to solve this problem. We show with simulations that a method we call consensus non-negative matrix factorization (cNMF) accurately infers identity and activity programs, including their relative contributions in each cell. To illustrate the insights this approach enables, we apply it to published brain organoid and visual cortex scRNA-Seq datasets; cNMF refines cell types and identifies both expected (e.g. cell cycle and hypoxia) and novel activity programs, including programs that may underlie a neurosecretory phenotype and synaptogenesis.},
  pmcid = {PMC6639075},
  pmid = {31282856},
  file = {/home/nguyenston/Zotero/storage/DS2HYKFQ/Kotliar et al. - Identifying gene expression programs of cell-type identity and cellular activity with single-cell RN.pdf}
}

@article{Buettner_FscLVM_ScalableVersatile_FA_2017,
  title = {F-{{scLVM}}: Scalable and Versatile Factor Analysis for Single-Cell {{RNA-seq}}},
  shorttitle = {F-{{scLVM}}},
  author = {Buettner, Florian and Pratanwanich, Naruemon and McCarthy, Davis J. and Marioni, John C. and Stegle, Oliver},
  year = {2017},
  month = nov,
  journal = {Genome Biology},
  volume = {18},
  number = {1},
  pages = {212},
  issn = {1474-760X},
  doi = {10.1186/s13059-017-1334-8},
  urldate = {2025-04-17},
  abstract = {Single-cell RNA-sequencing (scRNA-seq) allows studying heterogeneity in gene expression in large cell populations. Such heterogeneity can arise due to technical or biological factors, making decomposing sources of variation difficult. We here describe f-scLVM (factorial single-cell latent variable model), a method based on factor analysis that uses pathway annotations to guide the inference of interpretable factors underpinning the heterogeneity. Our model jointly estimates the relevance of individual factors, refines gene set annotations, and infers factors without annotation. In applications to multiple scRNA-seq datasets, we find that f-scLVM robustly decomposes scRNA-seq datasets into interpretable components, thereby facilitating the identification of novel subpopulations.},
  keywords = {Gene set annotations,Single-cell RNA-seq,Sparse factor analysis},
  file = {/home/nguyenston/Zotero/storage/J6ZSNVFR/Buettner et al. - 2017 - f-scLVM scalable and versatile factor analysis for single-cell RNA-seq.pdf}
}

@article{Levitin_DeNovo_Gene_Signature_Identification_2019,
  title = {De Novo Gene Signature Identification from Single-cell {{RNA}}-seq with Hierarchical {{Poisson}} Factorization},
  author = {Levitin, Hanna Mendes and Yuan, Jinzhou and Cheng, Yim Ling and Ruiz, Francisco JR and Bush, Erin C and Bruce, Jeffrey N and Canoll, Peter and Iavarone, Antonio and Lasorella, Anna and Blei, David M and Sims, Peter A},
  year = {2019},
  month = feb,
  journal = {Molecular Systems Biology},
  volume = {15},
  number = {2},
  pages = {e8557},
  issn = {1744-4292},
  doi = {10.15252/msb.20188557},
  urldate = {2025-04-17},
  abstract = {Common approaches to gene signature discovery in single-cell RNA-sequencing (scRNA-seq) depend upon predefined structures like clusters or pseudo-temporal order, require prior normalization, or do not account for the sparsity of single-cell data. We present single-cell hierarchical Poisson factorization (scHPF), a Bayesian factorization method that adapts hierarchical Poisson factorization (Gopalan et~al, , Proceedings of the 31st Conference on Uncertainty in Artificial Intelligence, 326) for de novo discovery of both continuous and discrete expression patterns from scRNA-seq. scHPF does not require prior normalization and captures statistical properties of single-cell data better than other methods in benchmark datasets. Applied to scRNA-seq of the core and margin of a high-grade glioma, scHPF uncovers marked differences in the abundance of glioma subpopulations across tumor regions and regionally associated expression biases within glioma subpopulations. scHFP revealed an expression signature that was spatially biased toward the glioma-infiltrated margins and associated with inferior survival in glioblastoma.},
  pmcid = {PMC6386217},
  pmid = {30796088},
  file = {/home/nguyenston/Zotero/storage/KDZL87LM/Levitin et al. - 2019 - De novo gene signature identification from single‐cell RNA‐seq with hierarchical Poisson factorizati.pdf}
}

@article{Risso_General_Flexible_Signal_Extract_2018,
  title = {A General and Flexible Method for Signal Extraction from Single-Cell {{RNA-seq}} Data},
  author = {Risso, Davide and Perraudeau, Fanny and Gribkova, Svetlana and Dudoit, Sandrine and Vert, Jean-Philippe},
  year = {2018},
  month = jan,
  journal = {Nature Communications},
  volume = {9},
  number = {1},
  pages = {284},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-02554-5},
  urldate = {2025-04-17},
  abstract = {Single-cell RNA-sequencing (scRNA-seq) is a powerful high-throughput technique that enables researchers to measure genome-wide transcription levels at the resolution of single cells. Because of the low amount of RNA present in a single cell, some genes may fail to be detected even though they are expressed; these genes are usually referred to as dropouts. Here, we present a general and flexible zero-inflated negative binomial model (ZINB-WaVE), which leads to low-dimensional representations of the data that account for zero inflation (dropouts), over-dispersion, and the count nature of the data. We demonstrate, with simulated and real data, that the model and its associated estimation procedure are able to give a more stable and accurate low-dimensional representation of the data than principal component analysis (PCA) and zero-inflated factor analysis (ZIFA), without the need for a preliminary normalization step.},
  copyright = {2018 The Author(s)},
  langid = {english},
  keywords = {Gene expression,Software,Statistical methods,Statistics,Transcriptomics},
  file = {/home/nguyenston/Zotero/storage/TSUGLYY4/Risso et al. - 2018 - A general and flexible method for signal extraction from single-cell RNA-seq data.pdf}
}

@article{Kinker_Pan_Cancer_2020,
  title = {Pan-Cancer Single Cell {{RNA-seq}} Uncovers Recurring Programs of Cellular Heterogeneity},
  author = {Kinker, Gabriela S. and Greenwald, Alissa C. and Tal, Rotem and Orlova, Zhanna and Cuoco, Michael S. and McFarland, James M. and Warren, Allison and Rodman, Christopher and Roth, Jennifer A. and Bender, Samantha A. and Kumar, Bhavna and Rocco, James W. and Fernandes, Pedro ACM and Mader, Christopher C. and {Keren-Shaul}, Hadas and Plotnikov, Alexander and Barr, Haim and Tsherniak, Aviad and {Rozenblatt-Rosen}, Orit and Krizhanovsky, Valery and Puram, Sidharth V. and Regev, Aviv and Tirosh, Itay},
  year = {2020},
  month = nov,
  journal = {Nature genetics},
  volume = {52},
  number = {11},
  pages = {1208--1218},
  issn = {1061-4036},
  doi = {10.1038/s41588-020-00726-6},
  urldate = {2025-04-17},
  abstract = {Cultured cell lines are the workhorse of cancer research, but it is unclear to what extent they recapitulate the cellular heterogeneity observed among malignant cells in tumors. To address this, we used multiplexed single cell RNA-seq to profile {\textasciitilde}200 cancer cell lines from 22 cancer types. We uncovered 12 expression programs that are recurrently heterogeneous within many cancer cell lines. These programs are associated with diverse biological processes including cell cycle, senescence, stress and interferon responses, epithelial-mesenchymal transition, and protein maturation and degradation. Notably, most of these recurrent programs of heterogeneity recapitulate those recently observed within human tumors. The similarity to tumors allowed us to prioritize specific cell lines as model systems of cellular heterogeneity. We used two such models to demonstrate the regulation and dynamics of an epithelial senescence-related program that is observed in subpopulations of cells within cell lines and tumors. We further demonstrate unique drug responses of these subpopulations, highlighting their potential clinical significance. Our work describes the landscape of cellular heterogeneity within diverse cancer cell lines, and identifies recurrent patterns of heterogeneity that are shared between tumors and specific cell lines.},
  pmcid = {PMC8135089},
  pmid = {33128048},
  file = {/home/nguyenston/Zotero/storage/ZC2DQQPD/Kinker et al. - 2020 - Pan-cancer single cell RNA-seq uncovers recurring programs of cellular heterogeneity.pdf}
}

@article{Seplyarskiy_PopulationSequencingData_2021,
  title = {Population Sequencing Data Reveal a Compendium of Mutational Processes in Human Germline},
  author = {Seplyarskiy, Vladimir B and Soldatov, Ruslan A and Koch, Evan and McGinty, Ryan J and Goldmann, Jakob M and Hernandez, Ryan D and Barnes, Kathleen and Correa, Adolfo and Burchard, Esteban G and Ellinor, Patrick T and McGarvey, Stephen T and Mitchell, Braxton D and Vasan, Ramachandran S and Redline, Susan and Silverman, Edwin and Weiss, Scott T and Arnett, Donna K and Blangero, John and Boerwinkle, Eric and He, Jiang and Montgomery, Courtney and Rao, D C and Rotter, Jerome I and Taylor, Kent D and Brody, Jennifer A and Chen, Yii-Der Ida and {de Las Fuentes}, Lisa and Hwu, Chii-Min and Rich, Stephen S and Manichaikul, Ani W and Mychaleckyj, Josyf C and Palmer, Nicholette D and Smith, Jennifer A and Kardia, Sharon L R and Peyser, Patricia A and Bielak, Lawrence F and O'Connor, Timothy D and Emery, Leslie S and Gilissen, Christian and Wong, Wendy S W and Kharchenko, Peter V and Sunyaev, Shamil},
  year = {2021},
  month = aug,
  journal = {Science (New York, N.Y.)},
  volume = {373},
  number = {6558},
  pages = {1030--1035},
  issn = {0036-8075},
  doi = {10.1126/science.aba7408},
  urldate = {2025-04-17},
  abstract = {Mechanistic processes underlying human germline mutations remain largely unknown.Variation in mutation rate and spectra along the genome is informative about the biological mechanisms. We statistically decompose this variation into separate processes using a blind source separation technique. The analysis of a large-scale whole genome sequencing dataset (TOPMed) reveals nine processes that explain the variation in mutation properties between loci. Seven of these processes lend themselves to a biological interpretation. One process is driven by bulky DNA lesions that resolve asymmetrically with respect to transcription and replication. Two processes independently track direction of replication fork and replication timing. We identify a mutagenic effect of active demethylation primarily acting in regulatory regions. We also demonstrate that a recently discovered mutagenic process specific to oocytes can be localized solely from population sequencing data. This process is spread across all chromosomes and is highly asymmetric with respect to the direction of transcription, suggesting a major role of DNA damage.},
  pmcid = {PMC9217108},
  pmid = {34385354},
  file = {/home/nguyenston/Zotero/storage/46XDYG2V/Seplyarskiy et al. - 2021 - Population sequencing data reveal a compendium of mutational processes in human germline.pdf}
}

@misc{Moran_IdentifiableDeepGenerative_2022,
  title = {Identifiable {{Deep Generative Models}} via {{Sparse Decoding}}},
  author = {Moran, Gemma E. and Sridhar, Dhanya and Wang, Yixin and Blei, David M.},
  year = {2022},
  month = feb,
  number = {arXiv:2110.10804},
  eprint = {2110.10804},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.10804},
  urldate = {2025-04-17},
  abstract = {We develop the sparse VAE for unsupervised representation learning on high-dimensional data. The sparse VAE learns a set of latent factors (representations) which summarize the associations in the observed data features. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. As examples, in ratings data each movie is only described by a few genres; in text data each word is only applicable to a few topics; in genomics, each gene is active in only a few biological processes. We prove such sparse deep generative models are identifiable: with infinite data, the true model parameters can be learned. (In contrast, most deep generative models are not identifiable.) We empirically study the sparse VAE with both simulated and real data. We find that it recovers meaningful latent factors and has smaller heldout reconstruction error than related methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/nguyenston/Zotero/storage/YAK5RVBC/Moran et al. - 2022 - Identifiable Deep Generative Models via Sparse Decoding.pdf}
}

@article{Fevotte_NonlinearHyperspectralUnmixing_2015,
  title = {Nonlinear Hyperspectral Unmixing with Robust Nonnegative Matrix Factorization},
  author = {F{\'e}votte, C{\'e}dric and Dobigeon, Nicolas},
  year = {2015},
  month = dec,
  journal = {IEEE Transactions on Image Processing},
  volume = {24},
  number = {12},
  eprint = {1401.5649},
  primaryclass = {stat},
  pages = {4810--4819},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2015.2468177},
  urldate = {2025-05-05},
  abstract = {This paper introduces a robust mixing model to describe hyperspectral data resulting from the mixture of several pure spectral signatures. This new model not only generalizes the commonly used linear mixing model, but also allows for possible nonlinear effects to be easily handled, relying on mild assumptions regarding these nonlinearities. The standard nonnegativity and sum-to-one constraints inherent to spectral unmixing are coupled with a group-sparse constraint imposed on the nonlinearity component. This results in a new form of robust nonnegative matrix factorization. The data fidelity term is expressed as a {$\beta$}-divergence, a continuous family of dissimilarity measures that takes the squared Euclidean distance and the generalized Kullback-Leibler divergence as special cases. The penalized objective is minimized with a block-coordinate descent that involves majorization-minimization updates. Simulation results obtained on synthetic and real data show that the proposed strategy competes with state-of-the-art linear and nonlinear unmixing methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/nguyenston/Zotero/storage/GKXVNCW5/Févotte and Dobigeon - 2015 - Nonlinear hyperspectral unmixing with robust nonnegative matrix factorization.pdf}
}

@article{Rajabi_SpectralUnmixingHyperspectral_2015,
  title = {Spectral {{Unmixing}} of {{Hyperspectral Imagery}} Using {{Multilayer NMF}}},
  author = {Rajabi, Roozbeh and Ghassemian, Hassan},
  year = {2015},
  month = jan,
  journal = {IEEE Geoscience and Remote Sensing Letters},
  volume = {12},
  number = {1},
  eprint = {1408.2810},
  primaryclass = {cs},
  pages = {38--42},
  issn = {1545-598X, 1558-0571},
  doi = {10.1109/LGRS.2014.2325874},
  urldate = {2025-05-05},
  abstract = {Hyperspectral images contain mixed pixels due to low spatial resolution of hyperspectral sensors. Spectral unmixing problem refers to decomposing mixed pixels into a set of endmembers and abundance fractions. Due to nonnegativity constraint on abundance fractions, nonnegative matrix factorization (NMF) methods have been widely used for solving spectral unmixing problem. In this letter we proposed using multilayer NMF (MLNMF) for the purpose of hyperspectral unmixing. In this approach, spectral signature matrix can be modeled as a product of sparse matrices. In fact MLNMF decomposes the observation matrix iteratively in a number of layers. In each layer, we applied sparseness constraint on spectral signature matrix as well as on abundance fractions matrix. In this way signatures matrix can be sparsely decomposed despite the fact that it is not generally a sparse matrix. The proposed algorithm is applied on synthetic and real datasets. Synthetic data is generated based on endmembers from USGS spectral library. AVIRIS Cuprite dataset has been used as a real dataset for evaluation of proposed method. Results of experiments are quantified based on SAD and AAD measures. Results in comparison with previously proposed methods show that the multilayer approach can unmix data more effectively.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/nguyenston/Zotero/storage/D3BNWXLF/Rajabi and Ghassemian - 2015 - Spectral Unmixing of Hyperspectral Imagery using Multilayer NMF.pdf}
}

@article{Brook_Dust_over_Green_Canopy_2016,
  title = {Quantitative {{Detection}} of {{Settled Dust Over Green Canopy Using Sparse Unmixing}} of {{Airborne Hyperspectral Data}}},
  author = {Brook, Anna and Dor, Eyal Ben},
  year = {2016},
  month = feb,
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume = {9},
  number = {2},
  pages = {884--897},
  issn = {2151-1535},
  doi = {10.1109/JSTARS.2015.2489207},
  urldate = {2025-05-06},
  abstract = {The main task of environmental and geoscience applications is efficient and accurate quantitative classification of earth surfaces and spatial phenomena. In the past decade, there has been a significant interest in employing hyperspectral unmixing (HU) to retrieve accurate quantitative information latent in hyperspectral imagery data. Recently, the ground-truth and laboratory measured spectral signatures promoted by advanced algorithms are proposed as a new path toward solving the unmixing problem of hyperspectral imagery in semisupervised fashion. This paper suggests that the sensitivity of sparse unmixing techniques provides an ideal approach to extract and identify dust settled over/upon green vegetation canopy using hyperspectral airborne data. Among the available techniques, this study presents the results of seven selected algorithms: 1) non-negative matrix factorization (NMF); 2) {\textbackslash}textL\_1 sparsity-constrained NMF ({\textbackslash}textL\_1\_{\textbackslash}textNMF); 3) {\textbackslash}textL\_1/2 sparsity-constrained NMF ({\textbackslash}textL\_1/2\_{\textbackslash}textNMF); 4) graph regularized NMF ({\textbackslash}textG\_{\textbackslash}textNMF); 5) structured sparse NMF ({\textbackslash}textSS\_{\textbackslash}textNMF); 6) alternating least-square (ALS); and 7) Lin's projected gradient (LPG). The performance is evaluated on real hyperspectral imagery data via detailed experimental assessment. The results compared with performances of selected conventional unmixing techniques.},
  keywords = {\textL_1 sparsity-constrained NMF ( \textL_1_\textNMF ),\textL_1 sparsity-constrained NMF (\textL_1_\textNMF),\textL_1/2 sparsity-constrained NMF ( \textL_1/2_\textNMF ),\textL_1/2 sparsity-constrained NMF (\textL_1/2_\textNMF),Algorithm design and analysis,Alternating least-square (ALS),classification,Coal,Earth,feature-extraction,graph regularized NMF ( \textG_\textNMF ),graph regularized NMF (\textG_\textNMF),HU,Hyperspectral imaging,Libraries,Lin's projected gradient (LPG),sparse modeling,structured sparse NMF ( \textSS_\textNMF ),structured sparse NMF (\textSS_\textNMF)},
  file = {/home/nguyenston/Zotero/storage/628WKNVV/7312911.html}
}

@article{Ji_Estimatng_Vegetation_Fractional_Cover_2016,
  title = {Research on Linear and Nonlinear Spectral Mixture Models for Estimating Vegetation Fractional Cover of {{Nitraria}} Bushes},
  author = {Ji, Cuicui and Jia, Y. and Li, Xuan and Wang, Jw},
  year = {2016},
  month = nov,
  journal = {National Remote Sensing Bulletin},
  volume = {20},
  pages = {1402--1412},
  doi = {10.11834/jrs.20166020},
  abstract = {Sand invasion is intensified by the serious degradation and disappearance of Nitraria bushes, which has a serious effect on the oasis ecological security of deserts. Quantitative analysis of different multiple scattering factors in mixed spectral contribution for the ecological environment on deserts is particularly important. Timely monitoring of spatial and temporal variations in photosynthetic/non-photosynthetic vegetation(PV/NPV) fraction cover provides essential information for guiding management practices on land desertification and research on vegetation recession mechanism. In this paper, taking the typical vegetation of Nitraria bushes in Minqin County of Gansu Province as an example, mixed and endmember spectra, and fraction information were acquired by ground-controlling spectroscopy experiment. Then, the fractional cover of PV(fpv) and that of NPV (fnpv) were estimated by linear and nonlinear spectral mixture models (NSMM) (including Kernel NSMM (KNSMM) and bilinear spectral mixture model (BSMM)), respectively. Fully constrained least square method was adopted to mix the models, and the fraction of every endmember and the accuracy information of all the samples were calculated. The performances of the models were compared based on root mean square error (RMSE) of the unmixing model and accuracy of field validation, and the endmember fraction of field validation is based on the abundance of digital image classification by the neural network classification algorithm. Results show that (1) compared with the traditional three-endmember model (PV, NPV, and bare soil (BS)), the four-endmember model, which incorporates an additional shadow endmember, can effectively improve both the accuracy of spectral mixture model(RMSE decreased from 0.0429 to 0.0052 and improved 16\% in accuracy) and the estimation precision of fpv and fnpv(increased by 44\% and 83\%, respectively). (2)Moreover, the precision of the unmixing of model could be improved by BSMM considering the multiple scattering between NPV and BS endmembers. However, the improved precision was insignificant. Also, considering the nonlinear parameters, the performance of KNSMM was slightly lower than that of the LSMM model. (3) The validation RMSE of fpv was 0.1177(R{$^2$}=0.7049), and that of fnpv was 0.0835 (R{$^2$}=0.4896) with LSMM based on PV/NPV, BS, and shadow endmembers. Process monitoring describes the multiple photon-scattering effect among PV/NPV, BS, and shadows in Nitrariabushes. The selection and application of the types of NSMMs should be confirmed according to specific research object and the required precision. Shadows cannot be ignored in estimating vegetation fractional cover, especially in improving fnpv accuracy. This finding illustrates that the types and number of endmembers chosen are significant in improving the accuracy of fraction estimation. The conclusion also shows that LSMM is suitable to estimate fpv and fnpv of Nitraria bushes accurately based on PV/NPV, BS, and shadow endmembers.},
  file = {/home/nguyenston/Zotero/storage/7F4UNM99/Ji et al. - 2016 - Research on linear and nonlinear spectral mixture models for estimating vegetation fractional cover.pdf}
}

@article{Lin_RetrievingHydrousMinerals_2017,
  title = {Retrieving the Hydrous Minerals on {{Mars}} by Sparse Unmixing and the {{Hapke}} Model Using {{MRO}}/{{CRISM}} Data},
  author = {Lin, Honglei and Zhang, Xia},
  year = {2017},
  month = may,
  journal = {Icarus},
  volume = {288},
  pages = {160--171},
  issn = {0019-1035},
  doi = {10.1016/j.icarus.2017.01.019},
  urldate = {2025-05-06},
  abstract = {The hydrous minerals on Mars preserve records of potential past aqueous activity. Quantitative information regarding mineralogical composition would enable a better understanding of the formation processes of these hydrous minerals, and provide unique insights into ancient habitable environments and the geological evolution of Mars. The Compact Reconnaissance Imaging Spectrometer for Mars (CRISM) has the advantage of both a high spatial and spectral resolution, which makes it suitable for the quantitative analysis of minerals on Mars. However, few studies have attempted to quantitatively retrieve the mineralogical composition of hydrous minerals on Mars using visible-infrared (VISIR) hyperspectral data due to their distribution characteristics (relatively low concentrations, located primarily in Noachian terrain, and unclear or unknown background minerals) and limitations of the spectral unmixing algorithms. In this study, we developed a modified sparse unmixing (MSU) method, combining the Hapke model with sparse unmixing. The MSU method considers the nonlinear mixed effects of minerals and avoids the difficulty of determining the spectra and number of endmembers from the image. The proposed method was tested successfully using laboratory mixture spectra and an Airborne Visible Infrared Imaging Spectrometer (AVIRIS) image of the Cuprite site (Nevada, USA). Then it was applied to CRISM hyperspectral images over Gale crater. Areas of hydrous mineral distribution were first identified by spectral features of water and hydroxyl absorption. The MSU method was performed on these areas, and the abundances were retrieved. The results indicated that the hydrous minerals consisted mostly of hydrous silicates, with abundances of up to 35\%, as well as hydrous sulfates, with abundances {$\leq$}10\%. Several main subclasses of hydrous minerals (e.g., Fe/Mg phyllosilicate, prehnite, and kieserite) were retrieved. Among these, Fe/Mg- phyllosilicate was the most abundant, with abundances ranging up to almost 30\%, followed by prehnite and kieserite, with abundances lower than 15\%. Our results are consistent with related research and in situ analyses of data from the rover Curiosity; thus, our method has the potential to be widely used for quantitative mineralogical mapping at the global scale of the surface of Mars.},
  keywords = {Abundance,CRISM,Hydrous minerals,Mars,Spectral unmixing},
  file = {/home/nguyenston/Zotero/storage/M2X29UK6/S0019103516302809.html}
}

@misc{Zhao_ConvergenceAnalysisMU_2017,
  title = {A {{Unified Convergence Analysis}} of the {{Multiplicative Update Algorithm}} for {{Regularized Nonnegative Matrix Factorization}}},
  author = {Zhao, Renbo and Tan, Vincent Y. F.},
  year = {2017},
  month = jun,
  number = {arXiv:1609.00951},
  eprint = {1609.00951},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1609.00951},
  urldate = {2025-05-14},
  abstract = {The multiplicative update (MU) algorithm has been extensively used to estimate the basis and coefficient matrices in nonnegative matrix factorization (NMF) problems under a wide range of divergences and regularizers. However, theoretical convergence guarantees have only been derived for a few special divergences without regularization. In this work, we provide a conceptually simple, self-contained, and unified proof for the convergence of the MU algorithm applied on NMF with a wide range of divergences and regularizers. Our main result shows the sequence of iterates (i.e., pairs of basis and coefficient matrices) produced by the MU algorithm converges to the set of stationary points of the non-convex NMF optimization problem. Our proof strategy has the potential to open up new avenues for analyzing similar problems in machine learning and signal processing.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Theory,Mathematics - Information Theory,Mathematics - Optimization and Control,Statistics - Machine Learning},
  file = {/home/nguyenston/Zotero/storage/H8EYFMEU/Zhao and Tan - 2017 - A Unified Convergence Analysis of the Multiplicative Update Algorithm for Regularized Nonnegative Ma.pdf;/home/nguyenston/Zotero/storage/QSHQKE7Z/1609.html}
}

@misc{Devarajan_NMFdualdivergence_2019,
  title = {Non-Negative Matrix Factorization Based on Generalized Dual Divergence},
  author = {Devarajan, Karthik},
  year = {2019},
  month = may,
  number = {arXiv:1905.07034},
  eprint = {1905.07034},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1905.07034},
  urldate = {2025-05-15},
  abstract = {A theoretical framework for non-negative matrix factorization based on generalized dual Kullback-Leibler divergence, which includes members of the exponential family of models, is proposed. A family of algorithms is developed using this framework and its convergence proven using the Expectation-Maximization algorithm. The proposed approach generalizes some existing methods for different noise structures and contrasts with the recently proposed quasi-likelihood approach, thus providing a useful alternative for non-negative matrix factorizations. A measure to evaluate the goodness-of-fit of the resulting factorization is described. This framework can be adapted to include penalty, kernel and discriminant functions as well as tensors.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  file = {/home/nguyenston/Zotero/storage/CRYGLGV5/Devarajan - 2019 - Non-negative matrix factorization based on generalized dual divergence.pdf}
}

@article{Fu_IdentifiabilityNMF_2018,
  title = {On {{Identifiability}} of {{Nonnegative Matrix Factorization}}},
  author = {Fu, Xiao and Huang, Kejun and Sidiropoulos, Nicholas D.},
  year = {2018},
  month = mar,
  journal = {IEEE Signal Processing Letters},
  volume = {25},
  number = {3},
  eprint = {1709.00614},
  primaryclass = {cs},
  pages = {328--332},
  issn = {1070-9908, 1558-2361},
  doi = {10.1109/LSP.2018.2789405},
  urldate = {2025-05-17},
  abstract = {In this letter, we propose a new identification criterion that guarantees the recovery of the low-rank latent factors in the nonnegative matrix factorization (NMF) model, under mild conditions. Specifically, using the proposed criterion, it suffices to identify the latent factors if the rows of one factor are {\textbackslash}emph\{sufficiently scattered\} over the nonnegative orthant, while no structural assumption is imposed on the other factor except being full-rank. This is by far the mildest condition under which the latent factors are provably identifiable from the NMF model.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/nguyenston/Zotero/storage/P4TAR5MX/Fu et al. - 2018 - On Identifiability of Nonnegative Matrix Factorization.pdf}
}

@article{Anderson_AsymptoticFA_1988,
  title = {The {{Asymptotic Normal Distribution}} of {{Estimators}} in {{Factor Analysis}} under {{General Conditions}}},
  author = {Anderson, T. W. and Amemiya, Yasuo},
  year = {1988},
  journal = {The Annals of Statistics},
  volume = {16},
  number = {2},
  eprint = {2241755},
  eprinttype = {jstor},
  pages = {759--771},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  urldate = {2025-05-17},
  abstract = {Asymptotic properties of estimators for the confirmatory factor analysis model are discussed. The model is identified by restrictions on the elements of the factor loading matrix; the number of restrictions may exceed that required for identification. It is shown that a particular centering of the maximum likelihood estimator derived under assumed normality of observations yields an asymptotic normal distribution that is common to a wide class of distributions of the factor vectors and error vectors. In particular, the asymptotic covariance matrix of the factor loading estimator derived under the normal assumption is shown to be valid for the factor vectors containing a fixed part and a random part with any distribution having finite second moments and for the error vectors consisting of independent components with any distributions having finite second moments. Thus the asymptotic standard errors of the factor loading estimators computed by standard computer packages are valid for virtually any type of nonnormal factor analysis. The results are extended to certain structural equation models.}
}
@article{Anderson_AsymptoticPCA_1963,
  title = {Asymptotic {{Theory}} for {{Principal Component Analysis}}},
  author = {Anderson, T. W.},
  year = {1963},
  journal = {The Annals of Mathematical Statistics},
  volume = {34},
  number = {1},
  eprint = {2991288},
  eprinttype = {jstor},
  pages = {122--148},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851},
  urldate = {2025-05-17}
}

@article{Bai_DeterminingNumberFactors_2002,
  title = {Determining the {{Number}} of {{Factors}} in {{Approximate Factor Models}}},
  author = {Bai, Jushan and Ng, Serena},
  year = {2002},
  month = jan,
  journal = {Econometrica},
  volume = {70},
  number = {1},
  pages = {191--221},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0012-9682},
  doi = {10.1111/1468-0262.00273},
  urldate = {2025-06-10},
  abstract = {In this paper we develop some econometric theory for factor models of large dimensions. The focus is the determination of the number of factors (r), which is an unresolved issue in the rapidly growing literature on multifactor models. We first establish the convergence rate for the factor estimates that will allow for consistent estimation of r. We then propose some panel criteria and show that the number of factors can be consistently estimated using the criteria. The theory is developed under the framework of large cross-sections (N) and large time dimensions (T). No restriction is imposed on the relation between N and T. Simulations show that the proposed criteria have good finite sample properties in many configurations of the panel data encountered in practice.},
  keywords = {asset pricing,factor analysis,model selection,principal components},
  file = {/home/nguyenston/Zotero/storage/BRSWAIMZ/Bai and Ng - 2002 - Determining the Number of Factors in Approximate Factor Models.pdf}
}

@article{Jaspers_BayesianEstimationMixtureCovariate_2018,
  title = {Bayesian Estimation of Multivariate Normal Mixtures with Covariate-Dependent Mixing Weights, with an Application in Antimicrobial Resistance Monitoring},
  author = {Jaspers, Stijn and Kom{\'a}rek, Arno{\v s}t and Aerts, Marc},
  year = {2018},
  journal = {Biometrical Journal},
  volume = {60},
  number = {1},
  pages = {7--19},
  issn = {1521-4036},
  doi = {10.1002/bimj.201600253},
  urldate = {2025-06-24},
  abstract = {Bacteria with a reduced susceptibility against antimicrobials pose a major threat to public health. Therefore, large programs have been set up to collect minimum inhibition concentration (MIC) values. These values can be used to monitor the distribution of the nonsusceptible isolates in the general population. Data are collected within several countries and over a number of years. In addition, the sampled bacterial isolates were not tested for susceptibility against one antimicrobial, but rather against an entire range of substances. Interest is therefore in the analysis of the joint distribution of MIC data on two or more antimicrobials, while accounting for a possible effect of covariates. In this regard, we present a Bayesian semiparametric density estimation routine, based on multivariate Gaussian mixtures. The mixing weights are allowed to depend on certain covariates, thereby allowing the user to detect certain changes over, for example, time. The new approach was applied to data collected in Europe in 2010, 2012, and 2013. We investigated the susceptibility of Escherichia coli isolates against ampicillin and trimethoprim, where we found that there seems to be a significant increase in the proportion of nonsusceptible isolates. In addition, a simulation study was carried out, showing the promising behavior of the proposed method in the field of antimicrobial resistance.},
  copyright = {{\copyright} 2017 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
  langid = {english},
  keywords = {antimicrobial resistance,censored data,clustering,multivariate normal mixture},
  file = {/home/nguyenston/Zotero/storage/ZSGRFMRR/Jaspers et al. - 2018 - Bayesian estimation of multivariate normal mixtures with covariate-dependent mixing weights, with an.pdf;/home/nguyenston/Zotero/storage/UZV2SMAF/bimj.html}
}

@article{Huang_MixtureRegressionModels_2012,
  title = {Mixture of {{Regression Models With Varying Mixing Proportions}}: {{A Semiparametric Approach}}},
  shorttitle = {Mixture of {{Regression Models With Varying Mixing Proportions}}},
  author = {Huang, Mian and Yao, Weixin},
  year = {2012},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {107},
  number = {498},
  pages = {711--724},
  publisher = {ASA Website},
  issn = {0162-1459},
  doi = {10.1080/01621459.2012.682541},
  urldate = {2025-06-24},
  file = {/home/nguyenston/Zotero/storage/6UUT3ETA/Huang and and Yao - 2012 - Mixture of Regression Models With Varying Mixing Proportions A Semiparametric Approach.pdf}
}

@book{cover2006elements,
  title={Elements of Information Theory},
  author={Cover, Thomas M. and Thomas, Joy A.},
  year={2006},
  edition={2nd},
  publisher={Wiley-Interscience},
  address={Hoboken, NJ}
}

@article{Chung_jackstraw,
    author = {Chung, Neo Christopher and Storey, John D.},
    title = {Statistical significance of variables driving systematic variation in high-dimensional data},
    journal = {Bioinformatics},
    volume = {31},
    number = {4},
    pages = {545-554},
    year={2015},
    month = {2},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btu674},
    url = {https://doi.org/10.1093/bioinformatics/btu674},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/31/4/545/49011114/bioinformatics\_31\_4\_545.pdf},
}




@inproceedings{Kingma2014, 
  year     = {2014}, 
  rating   = {0}, 
  keywords = {variational inference}, 
  author   = {Kingma, Diederik P and Welling, Max}, 
  title    = {Auto-Encoding Variational Bayes}, 
  urldate  = {0}, 
  series   = {International Conference on Learning Representations}
}
@article{rohe2023vintage-7f4, 
  year    = {2023}, 
  title   = {Vintage factor analysis with Varimax performs statistical inference}, 
  author  = {Rohe, Karl and Zeng, Muzhe}, 
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology}, 
  issn    = {1369-7412}, 
  doi     = {10.1093/jrsssb/qkad029}, 
  pages   = {1037--1060}, 
  number  = {4}, 
  volume  = {85}
}
@article{Anandkumar2014uc, 
  year     = {2014}, 
  rating   = {0}, 
  keywords = {latent variable models, method of moments, mixture models, tensor methods, To Read, topic modeling}, 
  title    = {Tensor Decompositions for Learning Latent Variable Models}, 
  author   = {Anandkumar, A. and Ge, R and Hsu, Daniel and Kakade, S. M.}, 
  pages    = {2773 -- 2883}, 
  volume   = {15}
}
@article{Kingma2019VAEs, 
  year    = {2019}, 
  title   = {An Introduction to Variational Autoencoders}, 
  author  = {Kingma, Diederik P. and Welling, Max}, 
  journal = {Foundations and Trends in Machine Learning}, 
  issn    = {1935-8237}, 
  doi     = {10.1561/2200000056}, 
  eprint  = {1906.02691}, 
  pages   = {307--392}, 
  number  = {4}, 
  volume  = {12}
}

@article{brunet_CCC_2004a,
  title = {Metagenes and Molecular Pattern Discovery Using Matrix Factorization},
  author = {Brunet, Jean-Philippe and Tamayo, Pablo and Golub, Todd R. and Mesirov, Jill P.},
  year = {2004},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {101},
  number = {12},
  pages = {4164--4169},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.0308531101},
  urldate = {2025-09-05},
  abstract = {We describe here the use of nonnegative matrix factorization (NMF), an algorithm based on decomposition by parts that can reduce the dimension of expression data from thousands of genes to a handful of metagenes. Coupled with a model selection mechanism, adapted to work for any stochastic clustering algorithm, NMF is an efficient method for identification of distinct molecular patterns and provides a powerful method for class discovery. We demonstrate the ability of NMF to recover meaningful biological information from cancer-related microarray data. NMF appears to have advantages over other methods such as hierarchical clustering or self-organizing maps. We found it less sensitive to a priori selection of genes or initial conditions and able to detect alternative or context-dependent patterns of gene expression in complex biological systems. This ability, similar to semantic polysemy in text, provides a general method for robust molecular pattern discovery.},
  file = {/home/nguyenston/Zotero/storage/PEUIN6QJ/Brunet et al. - 2004 - Metagenes and molecular pattern discovery using matrix factorization.pdf}
}
@article{islam_sigprofiler_extractor_2022,
  title = {Uncovering Novel Mutational Signatures by de Novo Extraction with {{SigProfilerExtractor}}},
  author = {Islam, S. M. Ashiqul and {D{\'i}az-Gay}, Marcos and Wu, Yang and Barnes, Mark and Vangara, Raviteja and Bergstrom, Erik N. and He, Yudou and Vella, Mike and Wang, Jingwei and Teague, Jon W. and Clapham, Peter and Moody, Sarah and Senkin, Sergey and Li, Yun Rose and Riva, Laura and Zhang, Tongwu and Gruber, Andreas J. and Steele, Christopher D. and Otlu, Bur{\c c}ak and Khandekar, Azhar and Abbasi, Ammal and Humphreys, Laura and Syulyukina, Natalia and Brady, Samuel W. and Alexandrov, Boian S. and Pillay, Nischalan and Zhang, Jinghui and Adams, David J. and Martincorena, I{\~n}igo and Wedge, David C. and Landi, Maria Teresa and Brennan, Paul and Stratton, Michael R. and Rozen, Steven G. and Alexandrov, Ludmil B.},
  year = {2022},
  month = nov,
  journal = {Cell Genomics},
  volume = {2},
  number = {11},
  publisher = {Elsevier},
  issn = {2666-979X},
  doi = {10.1016/j.xgen.2022.100179},
  urldate = {2025-09-05},
  langid = {english},
  pmid = {36388765},
  keywords = {cancer genomics,genomics,mutagenesis,mutational signatures},
  file = {/home/nguyenston/Zotero/storage/B3GG8Y4H/Islam et al. - 2022 - Uncovering novel mutational signatures by de novo extraction with SigProfilerExtractor.pdf}
}

